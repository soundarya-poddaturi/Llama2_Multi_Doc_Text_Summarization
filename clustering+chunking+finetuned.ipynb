{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wptzjSY9Cq5Y",
        "outputId": "648c3707-8bcd-4704-8ce1-790fe338263b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XzT5VyVaZdBD"
      },
      "outputs": [],
      "source": [
        "# !df -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW9XSdx57kFx",
        "outputId": "9f84be04-783c-4d8e-bde8-945ec9ac4d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token 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\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBnK4mR0C9yY",
        "outputId": "dcb21956-3401-4b59-f128-25ce43e94d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "ba8aa3c837b14885b35579e4c885a73b",
            "78d8d13099324d13945342a280aa9a49",
            "f6fb97b80a464613948ebfa63af3334a",
            "48de420e582c4a278785416584c868d6",
            "f465282061ff444faea61579ba088315",
            "0b00ce229f944fc3844e5d72b51ead79",
            "c00a53d07725457394181dfcaf1294be",
            "e0782cbade2f4ff3a6c222ddf78512de",
            "088db205eea7448781a90a2d8eb53198",
            "29d5be8a84a941918635c108421fb693",
            "304292dda28f4ed59794dc03c48e7b51",
            "0e65a9bc0e6341a284ed41cf5403401e",
            "25fd421e2e5d433f8c7afeb43b0d56e4",
            "b53cdcfaa6284ba093191f567fd1492d",
            "e8080ac9f5fd4772a95568a208ebcd3d",
            "2d73c7e3b05e4275a837dcd02fcfc56d",
            "c7a6adb970ae4b01808d29966317f46f",
            "ce3bfd833df5439cb43687275ca3e097",
            "5e8803b1cccf4a6e91800cbe3de80ae7",
            "ecda5a77fbfe437ab6fdb290996dc2f1",
            "d4b2478c88ba4f74bee7fbe72de98248",
            "00b70f9383314139ac427a26629e420c",
            "b7090ec5683a48ef9553f598a11ed6bf",
            "9bd0b9542f9a4cfa974722c247f6ece0",
            "f20ddd7868a84e40a7954063c952a4d2",
            "56abc4ccd8054dc18ebd7d141af54222",
            "9752074130a1441cbe350d5108d6ec4b",
            "a1955c15c35f42c28f85b6917b67a53f",
            "ea558a89c5204ee0bb962a0d9a572b37",
            "a50f9c6400bb4bcabdc225fc01b4a3c3",
            "15574030ede44d59a1b922a158b8fa76",
            "db419750178a4ce88795795fa9d4568b",
            "b09a75d90ceb4568bc4a6b336b8758c7",
            "d9060a88461544329097b37afb90651f",
            "3d9ffbe4f3a947989e15a1984b45c89f",
            "423723c7325f4712bfeb85a3ffdd6a2b",
            "c490ba341984466e9e36b15091fea74e",
            "d6eac16872e34c5ea014709b742ae9ef",
            "e33ac625e2d64948b771661f0b57023a",
            "c7d8f36b2ac04aba81ada4a41defca35",
            "e6a6d4762508481d9384251fbae5151b",
            "0c71bde575dd4840a4a27cfbcf151cc7",
            "855503613bc644babcb778b61bb79e51",
            "140a750fae3d47cfb491f6c5f7e35eed",
            "331d5c23847f4745b2167da765198ceb",
            "f95058c7fee5458293cfdaf5b7c8b10c",
            "2763e2f5c42f4b149a37cd23eaf18677",
            "02fd78e129364822b2c24fbee6c037f7",
            "7493b4cb44af4ed5b3b9c64876bdfab9",
            "96be09472ad64a468aefd0b43c99ca65",
            "9dccfed5a1cd42bdac89d3b2a7cf68f6",
            "b9de020ddb6742218f6e2112f281babc",
            "c2221dbe36d248aebaee8c8b9ff9a649",
            "e7d045d436c64e2a92b75fc6a8c51f40",
            "5459d1f8ac8640b0bedb5adbdd0824f5",
            "ddbbd456bffb4ff0a488ce2a3df13222",
            "2a758a3a400c4ef8924a9cb2644fb397",
            "9f87901282594b7cbb13a621a62ab6f1",
            "8b190f02ef1847b3aee33547748ea2ba",
            "709e2e30309a4b4f908084a11e74d286",
            "195fa9ac9d8140d4aff78d81abe4829d",
            "08c58b1861be41a990b777daa018eef6",
            "f990061922a8484d9788a687f25a33de",
            "c3e71f5480ff402b873372e8bd047a38",
            "f39c29c41e144cc4b24c26f32e31a77b",
            "822278b5294149aa81c88d16187b4a9e",
            "e8eb8e2f986444e38612953e855a1f13",
            "872006a114304cb095918a0bd50f8e2f",
            "f625e39f257a42258ffca3753acecc9d",
            "dff34ad65c3c4963aaeeab7616daf9dc",
            "7f960056efdd4501be0b6d9328ade427",
            "d7fa6df0a9bd480392fd51cfc56b1b62",
            "66f7228aa1c9437e933059b477ad3522",
            "9e4259477aab47898449db1940bc750e",
            "2ef0f583e6644a1891daa46da8ce8fd5",
            "ab0ef9f4788d4bedb335b63a61dc679c",
            "acc80baab5184bcbbf1d6124b8db3223",
            "ed8ba9d28d5a45829122a550c726002e",
            "d1effc167f6d424ca222da0a7a875436",
            "f44439ccfbdb443d891b577bff9c0ff7",
            "6b17003098ac440c972c1edb355d2ec7",
            "d49d866edee74c0ca973a49776959d95",
            "955004c55c424085b8f9346dd962ecd0",
            "15d18b6b9d604065ba17cf16ec75d4a9",
            "ff6024061a054cedbdb866c3585f48fe",
            "b9f34e57064d4fd09a60ae2554a9c748",
            "5cd3c1f77ad549e4a81a6edf0d86b6a7",
            "ee624b8c249d4aeca04fb8f41e9d1731",
            "dc81683b9c054317bb38df7f5d0daf11",
            "1923c3c32ead465ab871bdf15568434c",
            "94d27b4ee56f4c6487d68d984151ae75",
            "5daff8b92c2a4b87896449d8fb3f4504",
            "2d990a598f454862a1f8937017ef8524",
            "784ea746282d4389b03b631ce1703887",
            "d5700c3910af4ae2959a8744076c3958",
            "cc0f7a5cb90f458291d8402c8b90232d",
            "ba772723287b476d823b802663688fee",
            "000c79839ef14fa19d85e2ecb68557cf",
            "20e378b9064c44a584156b00828a326b",
            "6d7ad4a0593f4142bd4f6486f17d3e10",
            "7b9002b3913645c1ba60bf3f87775994",
            "0abad186d2ab4ed08ee3eed7c7c85b49",
            "7e67f77d1c634a398278c7b02a415a82",
            "b6ae04cf11a84b40a8c8caa34f48f06e",
            "52c40e59923e4e7e96f8424036d35dcd",
            "4dc2b5cfe95640d7b1143dfa0a2b6e13",
            "eba0b7538e0046e2bc43a845fac510cf",
            "c42d8ff330ed4dd492e5b27203faeafc",
            "0f5a12f0ddc2465bb245ec553419ca18",
            "85d42786d2234386bf50d7744fd04cc1"
          ]
        },
        "id": "SNu9GNwlCr1R",
        "outputId": "87769cdf-5891-4c4f-9f25-42a1f4b6c178"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba8aa3c837b14885b35579e4c885a73b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e65a9bc0e6341a284ed41cf5403401e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7090ec5683a48ef9553f598a11ed6bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9060a88461544329097b37afb90651f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "331d5c23847f4745b2167da765198ceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddbbd456bffb4ff0a488ce2a3df13222"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8eb8e2f986444e38612953e855a1f13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed8ba9d28d5a45829122a550c726002e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc81683b9c054317bb38df7f5d0daf11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7ad4a0593f4142bd4f6486f17d3e10"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model1 = \"\"\n",
        "model = \"soundarya2873/llama-2-7b-chat-finetuned1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "pipeline = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer= tokenizer,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                device_map=\"auto\",\n",
        "                max_new_tokens = 512,\n",
        "                do_sample=True,\n",
        "                top_k=30,\n",
        "                num_return_sequences=1,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LL7JGQ5iCzIy"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OQT5L5DQMEaB"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rdEbOPmYSysU"
      },
      "outputs": [],
      "source": [
        "text='''\n",
        "\"computing\" refers to the process of using computers and computer systems to perform various\n",
        "tasks, such as data processing, information storage, and solving complex problems .\n",
        "this computing can be either done in serial way known as serial computing or in parallel wa y\n",
        "known as parallel computing\n",
        "serial computing:\n",
        "serial computing refers to traditional computing where tasks are executed sequentially, one after\n",
        "the other, using a single processor. in serial computing, each instruction or task must wait for the\n",
        "previous one to complete before it can be executed. this approach limits the speed and efficiency\n",
        "of processing, especially when dealing with complex or time -consuming tasks. computing\n",
        "serial or\n",
        "sequential parallel example of serial computing : consider a task of sorting a large dataset of numbers in ascending\n",
        "order. in a serial computing environment, a single processor would go through the entire dataset,\n",
        "comparing and rearranging numbers one pair at a time until the entire dataset is sorted. this process\n",
        "occurs sequentially, and each comparison and rearrangement must wait for the previous one to\n",
        "finish.\n",
        "parallel computing\n",
        "parallel computing is a type of computation in which multiple processors or computers work together\n",
        "to solve a problem. instead of one single processor handling the entire task, parallel computing divides\n",
        "the task into smaller sub -tasks that can be processed simultaneously. this simultaneous processing\n",
        "can lead to significant improvements in computational speed and efficien cy.\n",
        "example of parallel computing: using the same example of sorting a large dataset, parallel computing\n",
        "would involve dividing the dataset into smaller chunks, and each chunk is sorted independently by a\n",
        "separate processor. these processors work in parall el, sorting their respective chunks simultaneously.\n",
        "once all processors have completed sorting their portions, the sorted chunks can be combined to\n",
        "produce the final sorted dataset.\n",
        "definition parallel computing is the practice of identifying and exposing parallelism in algorithms,\n",
        "expressing this in our software, and understanding the costs, benefits, and limitations of the chosen\n",
        "implementation.\n",
        "benefits of parallel computing\n",
        "\n",
        " faster run time with more compute cores: parallelization involves dividing a task into\n",
        "smaller sub -tasks that can be executed simultaneously, utilizing multiple cores to process the\n",
        "data. this approach can significantly reduce the time required to complete the task, as each\n",
        "core works on a separate portion of the problem concurrently.\n",
        " larger problem sizes with more compute nodes : with more nodes, you can break down your\n",
        "problem into smaller pieces that each node can work on simultaneously, which is especially\n",
        "beneficial for handling larger datasets and more complex simulations .\n",
        " energy efficiency by doing more with less: in the context of parallel computing, the concept\n",
        "of \"doing more with less\" often revolves around optimizing energy efficiency while achieving\n",
        "better computational performance.this can be achieved by making use of dynamic resource\n",
        "allocation and workload consolidation to ensure that the number of processors used is\n",
        "proportional to the workload. turn off or put to sleep any unused processors.\n",
        "the energy consumption for your applicat ion can be estimated using the formula\n",
        "p = (n processors) × (r watts/processors) × (t hours)\n",
        "where p is the energy consumption, n is the number of processors, r is the thermal design\n",
        "power, and t is the application run time.\n",
        "\n",
        " scalability : parallel computing can be easily scaled by adding more processors, which further\n",
        "enhances performance. serial computing does not scale in this manner, as it relies on a single\n",
        "processor.\n",
        " parallel computing can reduce costs: as technology advances, the cost of individual\n",
        "processors and memory decreases. parallel computing systems can take advantage of these\n",
        "cost reductions, making it more economical to build high -performance computing clusters or\n",
        "data centers .\n",
        "applications of parallel computing:\n",
        " scientific simulations: used in fields such as physics, chemistry, and engineering for\n",
        "complex simulations.\n",
        " big data processing: parallel computing is crucial in processing vast amounts of data in\n",
        "fields like data analytics and machine learning.\n",
        " weather forecasting: enables complex weather simulations and predictions.\n",
        " video and image processing: parallelism accelerates tasks like video rendering and\n",
        "image recognition.\n",
        " financial modelling : used for risk analysis, option pricing, and other complex financial\n",
        "calculations.\n",
        "fundamental laws\n",
        "fundamental laws in parallel computing, such as amdahl's law and gustafson's law, are essential\n",
        "for understanding the limitations and possibilities of parallel processing. these laws provide valuable\n",
        "insights into how the speedup of a parallel algorithm is affected by various factors .\n",
        "what is speedup?\n",
        "speedup in parallel computing refers to the performance improvement achieved by using multiple\n",
        "processors or computing resources to solve a problem compared to using a single processor. it is a\n",
        "measure of how much faster a parallel algorithm or system can complet e a task compared to a serial\n",
        "(single -processor) implementation of the same task. speedup is a crucial metric for evaluating the\n",
        "effectiveness of parallel computing systems.\n",
        "the speedup ( s) can be calculated using the following formula:\n",
        "s=tserial / tparallel\n",
        "where:\n",
        " tserial is the execution time of the task using a single processor (serial execution time).\n",
        "tparallel is the execution time of the task using multiple processors (parallel execution time).\n",
        "a speedup value greater than 1 indicates that the parallel implementation is faster than the serial\n",
        "implementation. ideally, in a perfectly parallelizable task, doubling the number of processors would ideally halve the execution time, resulting in a speedup of 2. however, achieving perfect linear\n",
        "spee dup is rare in real -world scenarios due to factors such as communication overhead, load\n",
        "balancing issues, and synchronization constraints between processors.\n",
        "\n",
        "amdahl's law is a fundamental principle in parallel computing that expresses the potential\n",
        "speedup of a parallel algorithm as a function of the proportion of the algorithm that can be\n",
        "parallelized. it was formulated by gene amdahl in 1967 and is represented by the fol lowing\n",
        "formula:\n",
        "where:\n",
        " speedup is the improvement in performance achieved by parallelizing a computation\n",
        "compared to executing it sequentially.\n",
        " p is the proportion of the algorithm that can be parallelized (a value between 0 and 1).\n",
        " s is the serial fraction\n",
        " n – no.of processors/nodes/cores\n",
        "amdahl's law highlights the limitations of parallel computing. it states that the speedup of a\n",
        "program using multiple processors in parallel computing is limited by the sequential fraction of\n",
        "the program. in other words, if only a portion of a program can be parallelized (the rest being\n",
        "inherently sequential), then no matter how many processors are added, there will always be a\n",
        "limit to the speedup that can be achieved.\n",
        "for example, if 90% of a program can be parall elized (p = 0.9) and the parallel portion runs on\n",
        "5 processors , the maximum speedup that can be achieved according to amdahl's law is:\n",
        "speedup= 1/(0.1+(0.9/5))=3.57\n",
        "in this case, even though 90% of the program can be parallelized and runs on 5 processors , the\n",
        "maximum speedup achievable is approximately 3.57 times faster compared to the sequential\n",
        "execution due to the presence of the 10% sequential portion.\n",
        "fig : speedup for a fixed -size problem according to amdahl’s law is shown as a function of the\n",
        "number of processors. lines show ideal speedup when 100% of an algorithm is parallelized,\n",
        "and for 90%, 75%, and 50%. amdahl’s law states that speedup is limited by the fractions of\n",
        "code that remain serial.\n",
        "gustafson's law , formulated by john l. gustafson, provides a different perspective on parallel\n",
        "computing compared to amdahl's law. unlike amdahl's law, which focuses on fixed problem sizes,\n",
        "gustafson's law takes into account varying problem sizes. the basic idea behind g ustafson's law is\n",
        "that as the size of the problem increases, the impact of the parallelizable portion of the program\n",
        "becomes more significant, leading to better scalability. in other words, with larger problem sizes,\n",
        "parallel systems can achieve higher lev els of speedup.\n",
        "the formula for gustafson's law is as follows:\n",
        "speedup(n) = n – s * (n – 1) where n is the number of processors, and s is the serial fraction\n",
        "strong scaling and weak scaling are two different m etrics used to evaluate the performance of\n",
        "parallel computing systems, and they provide insights into how well a parallel algorithm or\n",
        "application can handle an increasing workload or an increasing number of processors. here's a\n",
        "comparison of strong scalin g and weak scaling:\n",
        "strong scaling:\n",
        "definition: strong scaling measures how the execution time of a fixed problem size decreases\n",
        "as the number of processors increases. in other words, it assesses how well a parallel system\n",
        "performs when the size of the problem remains constant, but the number of proces sors used\n",
        "to solve the problem increases.\n",
        "objective: the goal of strong scaling is to reduce the execution time for a fixed problem size by\n",
        "utilizing more processors. it aims to speed up the solution of a specific problem.\n",
        "scenario: strong scaling is applicable when the size of the problem is fixed, and the aim is to\n",
        "solve that problem faster by employing additional processors.\n",
        "\n",
        "2. weak scaling:\n",
        "definition: weak scaling measures how the execution time changes as both the problem size\n",
        "and the number of processors increase proportionally. in other words, it assesses how well a\n",
        "parallel system can handle larger workloads by adding more processors as the problem size\n",
        "grows.\n",
        "objective: the goal of weak scaling is to maintain a constant workload per processor as the size\n",
        "of the problem and the number of processors increase. it aims to solve larger problems in\n",
        "approximately the same amount of time per processor.\n",
        "scenario: weak scaling is applicable when the problem size can be increased, and the aim is to\n",
        "handle larger workloads by distributing the computational load across a larger number of\n",
        "processors.\n",
        "parallel approaches (flynn’s classification)\n",
        "\n",
        "flynn's classification is essential in the field of parallel computing because it provides a framework\n",
        "for understanding and categorizing different types of computer architectures based on the number\n",
        "of instruction streams and data streams. this classifica tion is named after michael j. flynn, who\n",
        "introduced it in 1966. flynn’s taxonomy is a useful tool for understanding different types of\n",
        "computer architectures and their strengths and weaknesses.\n",
        "\n",
        "the taxonomy highlights the importance of parallelism in modern computing and shows how\n",
        "different types of parallelism can be exploited to improve performance. it helps in designing and\n",
        "analyzing parallel processing systems\n",
        "\n",
        "1. single instruction single data (sisd ): in a sisd architecture, there is a single processor\n",
        "that executes a single instruction stream and operates on a single data stream. this is the\n",
        "simplest type of computer architecture and is used in most traditional computers.\n",
        "2. single instruction multiple data (simd ): in a simd architecture, there is a single\n",
        "processor that executes the same instruction on multiple data streams in parallel. this type of\n",
        "architecture is used in applications such as image and signal processing.\n",
        "\n",
        "3. multiple instruction single data (misd ): in a misd architecture, multiple processors\n",
        "execute different instructions on the same data stream. this type of architecture is not\n",
        "commonly used in practice, as it is difficult to find applications that can be decomposed into\n",
        "indepen dent instruction streams.\n",
        "\n",
        "4. multiple instruction multiple data (mimd ): in a mimd architecture, multiple processors\n",
        "execute different instructions on different data streams. this type of architecture is used in\n",
        "distributed computing, parallel processing, and other high -performance computing applications.\n",
        "parallel strategies\n",
        "parallel strategies\" typically refer to techniques and methods for parallel processing, which is the\n",
        "simultaneous execution of multiple tasks or processes to improve the efficiency and performance\n",
        "of a computer system. parallel strategies are commonly used in various computing domains, such\n",
        "as high -performance computing and distributed systems, to speed up computations and handle\n",
        "large volumes of data. here are some common parallel s trategies:\n",
        "data parallel approach\n",
        "data parallelism involves performing the same operation on multiple data elements simultaneously.\n",
        "this strategy is often used in applications where the same operation can be applied to different\n",
        "pieces of data independent ly.\n",
        "scenario : imagine you're running a data analysis task on a large dataset of customer reviews for a\n",
        "product. your goal is to perform sentiment analysis on each review to determine if it's positive,\n",
        "negative, or neutral. the sentiment analysis process is computationally intensive, and you want to\n",
        "speed it up using data parallelism.\n",
        "data parallelism in sentiment analysis :\n",
        "1. data preparation : you have a dataset of 1,000,000 customer reviews. to apply data\n",
        "parallelism, you divide this dataset into smaller, non-overlapping subsets. let's say you split\n",
        "it into four subsets, each containing 250,000 reviews.\n",
        "2. parallel processing : you have a sentiment analysis model that can analyze reviews. you set\n",
        "up four separate processing units (e.g., cpu cores or machines in a cluster), each responsible\n",
        "for analyzing one subset of reviews. each processing unit loads its assigned subset of data.\n",
        "3. analysis : each processing unit applies the sentiment analysis model to its subset of reviews\n",
        "independently and simultaneously. for in stance:\n",
        " processing unit 1 analyzes reviews 1 to 250,000.\n",
        " processing unit 2 analyzes reviews 250,001 to 500,000.\n",
        " processing unit 3 analyzes reviews 500,001 to 750,000.\n",
        " processing unit 4 analyzes reviews 750,001 to 1,000,000.\n",
        "4. aggregation : as each processing unit finishes its analysis, it generates results, such as counts\n",
        "of positive, negative, and neutral reviews within its subset. these results are temporarily\n",
        "stored.\n",
        "5. combining results : after all processing units have completed their work, you combine the\n",
        "results. you sum up the counts from each processing unit to get the overall sentiment\n",
        "analysis results for the entire dataset.\n",
        "task parallelism(main -worker approach)\n",
        "task parallelism involves executing multiple independent tasks or processes in parallel. each task\n",
        "can perform different operations and may not necessarily operate on the same data. task\n",
        "parallelism is common in applications where different tasks can be performed concurrently without\n",
        "dependencies between them.\n",
        "in the main -worker approach, one processor schedules and distributes the tasks for all the workers,\n",
        "and each worker checks for the next work item as it returns the previous completed task .\n",
        "example: web server handling requests\n",
        "consider a web server handling incoming http requests. each i ncoming request is an independent\n",
        "task that can be processed concurrently. the tasks include tasks like parsing the request, querying\n",
        "the database, and generating the response. in a task parallelism scenario:\n",
        "1. task 1: parsing request\n",
        " this task involves pars ing the incoming http request to extract information like the\n",
        "requested url, parameters, and headers.\n",
        "2. task 2: database query\n",
        " this task involves querying a database to fetch data related to the request, such as\n",
        "user information or product details.\n",
        "3. task 3: generating response\n",
        " this task involves generating an html response based on the parsed request and\n",
        "data retrieved from the database.\n",
        "in a task parallelism setup, these tasks can be executed concurrently by multiple threads or\n",
        "processes, allowing the server to handle multiple incoming requests simultaneously without waiting\n",
        "for one task to complete before starting the next.\n",
        "bucket -brigade parallelism :\n",
        "a bucket brigade is a method of manually transporting items or materials from one location to\n",
        "another by forming a line of people, each of whom carries an item and passes it to the next person.\n",
        "this technique is similar to how buckets of water might be passed along a line of people to put out a\n",
        "fire, which is where the term \"bucket brigade\" originated.\n",
        "in parallel computing, the concept of bucket -brigade parallelism involves breaking down a task into\n",
        "smaller subtasks, where each subtask is processed independently and passed to the next processing\n",
        "unit for further computation. this technique allows for efficient parallel processing of tasks and is\n",
        "often used in scenarios where tasks can be divided into smaller, manageable parts.\n",
        "example: manufacturing assembly line\n",
        "let's say we have a manufacturing assembly line for producing smartphones. the assembly line\n",
        "consists of three stages: a, b, and c. each stage represents a specific task in the smartphone\n",
        "assembly process.\n",
        "1. stage a - component assembly :\n",
        " worker a assembles the basic components of the smartphone, such as the circuit\n",
        "board, battery, and display. once worker a finishes assembling a smartphone, it passes it\n",
        "to stage b.\n",
        "2. stage b - software installation :\n",
        " worker b installs the operating system and necessary software onto the smartphone\n",
        "assembled by worker a. after software installation, the smartphone is passed to stage c.\n",
        "3. stage c - quality control and packaging :\n",
        " worker c checks the smartphone for quality control, ensuring that all components\n",
        "are working correctly an d the software is functioning as intended. if the smartphone passes\n",
        "quality control, it is packaged and prepared for shipment.\n",
        "in this example, each stage (a, b, and c) represents a processing step, similar to the stages in a\n",
        "bucket -brigade parallelism sce nario.\n",
        "parallel speedup versus comparative speedups.\n",
        "parallel speedup and comparative speedup are two different metrics used to evaluate the performance\n",
        "improvement achieved by parallel processing.\n",
        "parallel speedup measures how much faster a parallel algorithm runs compared to its sequential\n",
        "(single -processor) counterpart. it quantifies the performance improvement gained by using multiple\n",
        "processing units in parallel. parallel speedup is calculated using the followi ng formula:\n",
        "parallel speedup=sequential execution time/parallel execution\n",
        "in this formula:\n",
        " sequential execution time is the time taken by the algorithm to execute sequentially on a\n",
        "single processor.\n",
        " parallel execution time is the time taken by the paralle l algorithm to execute on multiple\n",
        "processors.\n",
        "comparative speedup : comparative speedup is between architectures. this is usually a\n",
        "performance comparison between two parallel implementations or other comparison between\n",
        "reasonably constrained sets of hardware. for example, it may be between a parallel mpi\n",
        "implementation on all the cores of the node of a computer versus the gpu(s) on a node\n",
        "how parallel computing works\n",
        "as a developer, you are responsible for the application software layer, which includes your source code.\n",
        "in the source code, you make choices about the programming language and parallel software interfaces\n",
        "you use to leverage the underlying hardware. additionally, you decide how to break up your work into\n",
        "parallel units. a compiler is designed to translate your source code into a form the hardware can execute.\n",
        "with these instructions at hand, an os manages executing these on the computer hardware.\n",
        "parallel approach models are used to express parallelization in an application software layer\n",
        "that gets mapped to the computer hardware through the compiler and the os. parallel computing\n",
        "approaches involve various models and paradigms that define how tasks are divided, coordinated, and\n",
        "executed in parallel systems. here are some common parallel computing approach models:\n",
        "hardware models\n",
        "distributed memory architecture: a cross -node parallel method :\n",
        "parallel approach models\n",
        "hardware models\n",
        "distributed memory architecture:\n",
        "a cross -node parallel method :\n",
        "shared memory architecture: an\n",
        "on-node parallel method\n",
        "vector units: multiple operations\n",
        "with one instruction\n",
        "accelerator device: a special -\n",
        "purpose add-on processor\n",
        "software models\n",
        "process -based parallelization :\n",
        "message passing\n",
        "thread -based parallelization :\n",
        "shared data via memory\n",
        "vectorization : multiple\n",
        "operations with one instruction\n",
        "stream processing : through\n",
        "specialized processors\n",
        "distributed memory architecture, also known as distributed memory parallelism, is a parallel\n",
        "computing method where multiple processors or nodes in a cluster have their own private memory.\n",
        "these nodes are connected via a network, and they communicate and coordinate with each other\n",
        "by passing messages. in this architecture, each node opera tes independently and has its own local\n",
        "memory, and data sharing is achieved explicitly through message passing.\n",
        "in the context of distributed memory architecture, a \"cross -node parallel method\" refers to parallel\n",
        "processing techniques that involve distributing tasks across multiple nodes in a cluster. each node\n",
        "works on its subset of the data or a specific portion of the computation. communication and\n",
        "coordination between nodes are essential, as tasks often depend on results or data computed on\n",
        "othe r nodes.\n",
        "shared memory architecture: an on-node parallel method\n",
        "in shared memory architecture, multiple processors or cores share a single, unified memory space.\n",
        "this shared memory can be accessed and modified by any processor within the system. on -node\n",
        "parallelism, within the context of shared memory architecture, ref ers to parallel processing\n",
        "techniques that occur on a single computing node. in this approach, multiple threads or processes\n",
        "run concurrently on the same node, accessing shared memory to perform computations .\n",
        "vector units: multiple operations with one instruction\n",
        "vector units, also known as vector processors, are specialized hardware units that can perform\n",
        "multiple operations with a single instruction. these units are designed to process vectors, which are\n",
        "arrays of data elements, simultaneously. vecto r processing is particularly useful in scenarios where\n",
        "the same operation needs to be performed on a large set of data elements .\n",
        "vector processing example with four array elements operated on simultaneously\n",
        "accelerator device: a special -purpose add-on processor\n",
        "gpus come in two varieties: integrated and discrete. discrete or dedicated gpus typically have a\n",
        "large number of streaming multiprocessors and their own dram. accessing data on a discrete gpu\n",
        "requires communication over a pci bus\n",
        "an accelerator device, often referred to as an accelerator, is a specialized hardware component\n",
        "(gpu) designed to perform specific types of computational tasks or workloads efficiently.\n",
        "accelerators are typically used in conjunction with a central processin g unit (cpu) and are especially\n",
        "well-suited for workloads that can benefit from parallel processing and offloading certain tasks from\n",
        "the cpu. accelerators are sometimes called \"add -on processors\" because they augment the\n",
        "processing capabilities of a syste m.\n",
        "general heterogeneous parallel architecture model\n",
        "now let’s combine all of these different hardware architectures into one model . two nodes, each\n",
        "with two cpus, share the same dram memory. each cpu is a dual -core processor with an\n",
        "integrated gpu. a discrete gpu on the pci bus also attaches to one of the cpus. though the cpus\n",
        "share main memory, these are commonly in different non -uniform memory access (numa)\n",
        "regions. this means that accessing the second cpu’s memory is more expensive than getting at it’s\n",
        "own memory\n",
        "fig 5: a general heterogeneous parallel architecture model consisting of two nodes connected by\n",
        "a network. each node has a multi -core cpu with an integrated and discrete gpu and some\n",
        "memory (dram).\n",
        "software models\n",
        "the programmer must first expose the parallelization, determine the best technique to operate in\n",
        "parallel, and then explicitly direct its operation in a safe, correct, and efficient manner. the following\n",
        "methods are the most common techniques for parallelization\n",
        " process -based parallelization : message passing\n",
        "process -based parallelization, particularly through message passing, is a common approach in\n",
        "parallel computing. it involves dividing a task into multiple processes or threads that run\n",
        "independently on separate computing nodes or cores. these processes communicate and\n",
        "coordinate with each other by sending and receiving messages. message passing is a method of\n",
        "inter -process communication where data and instructions are exchanged between processes to\n",
        "synch ronize and share information. this approach is widely used in distributed memory systems,\n",
        "such as clusters and supercomputers.\n",
        "fig 6 : the message passing library spawns processes. the os places the processes on the cores\n",
        "of two nodes. the question marks i ndicate that the os controls the placement of the processes\n",
        "and can move these during run time as indicated by the dashed arrows. the os also allocates\n",
        "memory for each process from the node’s main memory\n",
        " thread -based parallelization : shared data via memory\n",
        "thread -based parallelization involves dividing a task into multiple threads that share the same\n",
        "memory space within a single process. these threads can run concurrently on multiple cpu cores,\n",
        "and they communicate and coordinate by accessing shared data in the shared memory. this\n",
        "approach is commonly used in multi -core processors and symmetric multiprocessing (smp) systems.\n",
        "fig 7: the application process in a thread -based approach to parallelization spawns\n",
        "threads. the threads are restricted to the node’s domain. the question marks show that\n",
        "the os decides where to place the threads. some memory is shared between threads.\n",
        " vectorization : multiple operations with one instruction\n",
        "vectorization is a parallel computing technique that enables processors to perform multiple\n",
        "operations with a single instruction. it takes advantage of simd (single instruction, multiple data)\n",
        "capabilities found in modern processors, including cpus and gpus. simd allows a single instruction\n",
        "to operate on multiple da ta elements simultaneously, which can significantly accelerate\n",
        "computations involving large datasets.\n",
        " stream processing : through specialized processors\n",
        "stream processing, often referred to as stream computing or data stream processing, is a computing\n",
        "paradigm where data is continuously processed as it is generated or ingested, rather than being\n",
        "stored in traditional databases or file systems. stream proce ssing is particularly useful for handling\n",
        "large volumes of real -time data from various sources, such as sensors, social media, financial\n",
        "transactions, and iot devices. specialized processors designed for stream processing accelerate the\n",
        "analysis and manipu lation of data streams, ensuring timely and efficient processing\n",
        "in the stream processing approach, data and compute kernel are offloaded to the gpu and its\n",
        "streaming multiprocessors. processed data, or output, transfers back to the cpu for file io or other\n",
        "work\n",
        "sample application\n",
        "we start with a 2d problem domain of a region of space. for purposes of illustration, we will use\n",
        "a 2d image of the krakatau volcano as our example. the goal of our calculation could be to model\n",
        "the volcanic plume, the resulting tsunami, or the early detection of a volcanic eruption using\n",
        "machine learning. for all of these options, calculation speed is critical if we want real -time result s\n",
        "to inform our decisions.\n",
        "1. discretize (break up) the problem into smaller cells or elements\n",
        "2 . define a computational kernel (operation) to conduct on each element of the mesh\n",
        "3. add the following layers of parallelization on cpus and gpus to perfo rm the calculation:\n",
        "vectorization —work on more than one unit of data at a time\n",
        "4. threads —deploy more than one compute pathway to engage more processing cores\n",
        "5. processes —separate program instances to spread out the calculation into separate memory\n",
        "spaces\n",
        "6. off -loading the calculation to gpus —send the data to the graphics processor to calculate\n",
        "step 1: discretize the problem into smaller cells or elements\n",
        "the domain is discretized into cells. for each cell in the computational domain, properties such as\n",
        "wave height, fluid velocity, or smoke density are solved for according to physical laws. ultimately, a\n",
        "stencil operation or a matrix -vector system represents this discrete scheme\n",
        "step 2: define a computational kernel, or operation, to conduct on each element of the mesh\n",
        "the calculations on this discretized data are often some form of a stencil operation, so -called because\n",
        "it involves a pattern of a djacent cells to calculate the new value for each cell. this can be an average\n",
        "(a blur operation, which blurs the image )gradient (edge -detection, which sharpens the edges in the\n",
        "image) or another more complex operation associated with solving physical sys tems described by\n",
        "partial differential equations (pdes)\n",
        "step 3: vectorization to work on more than one unit of data at a time\n",
        "some processors have the ability to operate on more than one piece of data at a time; a capability\n",
        "referred to as vector operations. the shaded blocks in figure illustrate how multiple data values\n",
        "are operated on simultaneously in a vector unit in a proce ssor with one instruction in one clock\n",
        "cycle.\n",
        "step 4: threads to deploy more than one compute pathway to engage more processing cores\n",
        "because most cpus today have at least four processing cores, we use threading to operate the cores\n",
        "simultaneously acros s four rows at a time.\n",
        "step 5: processes to spread out the calculation to separate memory spaces\n",
        "we can further split the work between processors on two desktops, often called nodes in parallel\n",
        "processing. when the work is split across nodes, the memory spaces for each node are distinct and\n",
        "separate.\n",
        "step 6: off -loading the calculation to gpus\n",
        "on a gpu, the vector length is much larger than on a cpu. here, 8×8 tiles are distributed across\n",
        "gpu work groups.\n",
        "performance limits and profiling\n",
        "in parallel processing, understanding performance limits and profiling the application are crucial\n",
        "steps to optimize the execution of parallel programs.\n",
        "performance limits refer to the maximum achievable performance of a computing system or\n",
        "application un der specific conditions. these limits are determined by various factors and constraints\n",
        "and play a crucial role in understanding the capabilities and limitations of a system. understanding\n",
        "these performance limits is essential for designing efficient algor ithms, optimizing software, and\n",
        "choosing appropriate hardware configurations. it also guides researchers and engineers in\n",
        "developing new technologies to overcome existing limitations and improve overall computing\n",
        "performance.\n",
        "profiling tools are used to ga ther detailed information about the behavior of a parallel program. by\n",
        "understanding performance limits, utilizing profiling tools, and optimizing the code based on the\n",
        "profiling results, developers can enhance the efficiency of parallel applications, lea ding to improved\n",
        "speedup and overall performance.\n",
        "application’s potential performance limits\n",
        " flops (floating -point operations)\n",
        " ops (operations) that include all types of computer instructions\n",
        " memory bandwidth: rate at which the data is transferred\n",
        " memory latency: time required for the first byte or word of data to be transferred\n",
        " instruction queue (instruction cache)\n",
        " networks\n",
        " disk\n",
        " machine balance: number of flops executed /memory bandwidth\n",
        " arithmetic intensity : number of flops executed per memory operation\n",
        "all of these limitations can be divided into two major categories:. speeds are how fast operations can\n",
        "be done. it includes all types of computer operations. but to be able to do the operations, you must\n",
        "get the data there. this is where feeds come in. feeds include the memory bandwidth through the\n",
        "cache hierarchy, as well as network and disk bandwidth .\n",
        "for many applications, the memory bandwidth limit can be difficult especially dealing with non-\n",
        "contiguous bandwidth.it is also known as strided memory access or non -contiguous memory\n",
        "access, refers to the manner in which data elements are accessed in memory. in contrast to\n",
        "contiguous memory access, where elements are stored in consecutive memory locations, non -\n",
        "contiguous memory access invo lves accessing elements that are not stored sequentially in memory.\n",
        "non -contiguous memory access:\n",
        "now, consider a situation where the array elements are scattered in memory with a stride of 2. this\n",
        "is a non -contiguous memory access pattern:\n",
        "in this case, accessing every second element (stride = 2) would mean accessing memory locations 1,\n",
        "2, 3, 4, 5, etc., but the elements are not stored sequentially.\n",
        "when your program needs to access such non -contiguous elements, it may lead to inefficiencie s\n",
        "due to increased cache misses and a higher likelihood of accessing data from main memory rather\n",
        "than the faster cache memory.\n",
        "determine your hardware capabilities:\n",
        "to determine the performance of hardware the following metrics are used :\n",
        " the rate at which floating -point operations can be executed (flops/s)\n",
        " the rate at which data can be moved between various levels of memory (gb/s)\n",
        " the rate at which energy is used by your application (watts)\n",
        "in determining hardware performance and calculating the metrics , we use a mixture of theoretical\n",
        "and empirical measurements .\n",
        "theoretical measurements provide an upper limit to what a system can achieve. for instance, in\n",
        "parallel computing, theoretical analysis can reveal the maximum speedup or efficiency that a\n",
        "parallel algorithm can achieve in an ideal scenario .\n",
        "real -world validation is done by empirical measurements , they provide concrete evidence of how\n",
        "a system performs under real -world conditions, accounting for various factors like i/o operations,\n",
        "network latency, and concurrency issues.\n",
        "one of the best tools for understanding the hardware you run is the lstopo program (graphical view)\n",
        "and lscpu for text view . lstopo is bundled with the hwloc package that com es with nearly every mpi\n",
        "distribution. this command outputs a graphical view of the hardware on your system. figure below\n",
        "shows the output for a mac laptop in graphical view.\n",
        "text view\n",
        "the information from the lscpu command and the /proc/cpuinfo file helps to determine the number\n",
        "of processors, the processor model, the cache sizes, and the clock frequency for the system\n",
        "calculating theoretical maximum flops\n",
        "theoretical flops=number of cores×clock speed×flops per cycle per core\n",
        "where:\n",
        " number of cores: this represents the total number of processor cores in the computing\n",
        "system.\n",
        " clock speed: this indicates the clock speed of each core in the system, typically measured\n",
        "in hertz (hz) or gigahertz (ghz). it represents the number of cycles th e processor can\n",
        "execute per second.\n",
        " flops per cycle per core: this signifies the number of floating -point operations a core can\n",
        "perform in a single clock cycle. modern processors often perform multiple flops per cycle\n",
        "due to features like simd (single inst ruction, multiple data) operations.\n",
        "for example, let's consider a system with 4 cores, each operating at 3.0 ghz, and capable of\n",
        "executing 4 flops per cycle per core (assuming simd operations are utilized):\n",
        "theoretical flops=4 cores×3.0 ghz×4 flops per cycle per core\n",
        "theoretical flops=48 gflops\n",
        "the memory hierarchy and theoretical memory bandwidth\n",
        "we can calculate the theoretical memory bandwidth of the main memory using the memory chips\n",
        "specifications.\n",
        "the general formula is b t = mtr × mc × tw × ns = data transfer rate × memory channels × bytes\n",
        "per access × sockets\n",
        "processors are installed in a socket on the motherboard. the motherboard is the main system board\n",
        "of the computer, and the socket is the lo cation where the processor is inserted. most motherboards\n",
        "are single -socket, where only one processor can be installed. dual -socket motherboards are more\n",
        "common in high -performance computing systems. two processors can be installed in a dual -socket\n",
        "motherb oard, giving us more processing cores and more memory bandwidth.\n",
        "empirical measurement of bandwidth and flop\n",
        "the empirical bandwidth is the measurement of the fastest rate that memory can be loaded from\n",
        "main memory into the processor. if a single byte of m emory is requested, it takes 1 cycle to retrieve\n",
        "it from a cpu register. if it is not in the cpu register, it comes from the l1 cache. if it is not in the l1\n",
        "cache, the l1 cache loads it from l2 and so on to main memory. if it goes all the way to main\n",
        "memo ry, for a single byte of memory, it can take around 400 clock cycles. this time required for the\n",
        "first byte of data from each level of memory is called the memory latency .\n",
        "two different methods are used for measuring the bandwidth: the stream benchmark and the\n",
        "roofline model measured by the empirical roofline toolkit.\n",
        "key differences:\n",
        " focus: stream primarily focuses on memory bandwidth, providing quantitative\n",
        "measurements. in contrast, the roofline model provides a graphical representation of\n",
        "performance bottlenecks, considering both computational capabilities and memory\n",
        "bandwidth.\n",
        " representation: stream results in a numerical measurement (memory bandwidth in bytes\n",
        "per second), while the roofline model is a graphical representation that helps v isualize\n",
        "performance limitations.\n",
        " insights: stream provides detailed insights into memory subsystem performance, whereas\n",
        "the roofline model offers a high -level overview of an application's performance efficiency\n",
        "concerning hardware constraints.\n",
        "calculatin g the machine balance between flops and bandwidth\n",
        "the machine balance is the flops divided by the memory bandwidth.\n",
        "we can calculate both a theoretical machine balance (mb t) and an empirical machine balance (mb e)\n",
        "like so:\n",
        "mb t = f t / b t\n",
        "mb e = f e / b e\n",
        "characterizing your application: profiling\n",
        "now that you have some sense of what performance you can get with the hardware, you need to\n",
        "determine what are the performance characteristics of your application. additionally, you should\n",
        "develop an understandi ng of how different subroutines and functions depend on each other .\n",
        "profiling tools :\n",
        "using call graphs for hot -spot and dependency analysis\n",
        "in the context of parallel programming, call graphs are diagrams that represent the calling\n",
        "relationships between different functions or methods in a parallel program. they illustrate how\n",
        "functions or tasks invoke each other and provide a visual representation of the program's control\n",
        "flow. analyzing call graphs in parallel programming can provide valuable insights in to the program's\n",
        "structure, dependencies, and potential performance optimizations . by analyzing these call graphs,\n",
        "developers can identify hot -spots —functions or tasks that consume a significant amount of\n",
        "computational time. optimizing these hot -spots is e ssential for improving overall parallel program\n",
        "performance.\n",
        "empirical measurement of processor clock frequency and energy consumption\n",
        "empirical measurement of processor clock frequency:\n",
        "1. profiling tools: profiling tools like intel vtune profiler or amd codexl can provide insights\n",
        "into various performance metrics, including processor clock frequency. these tools often offer\n",
        "visualizations and detailed reports for better analysis.\n",
        "2. benchmarking suites: benchmarking tools like spec cpu benchmarks or hpc chal lenge\n",
        "benchmarks often include components that measure processor clock frequencies. running\n",
        "these benchmarks can provide detailed information about the processor's performance\n",
        "characteristics.\n",
        "2. empirical measurement of energy consumption:\n",
        "1. power measureme nt tools: use power measurement tools and hardware devices to\n",
        "measure the power consumption of your system. power meters and sensors can be attached\n",
        "to the system to measure real -time power usage. tools like intel power gadget or linux's\n",
        "powerstat can help measure power usage.\n",
        "2. energy profilers: some profiling tools, like intel vtune profiler, also offer energy profiling\n",
        "capabilities. they can provide insights into energy consumption patterns at different parts of\n",
        "your code. these tools often correlate energ y consumption with specific functions or code\n",
        "regions.\n",
        "tracking memory during run time\n",
        "tracking memory usage during runtime in parallel computing is crucial for optimizing performance,\n",
        "detecting memory leaks, and ensuring efficient memory management. several techniques and tools\n",
        "can help you monitor memory usage in parallel applications. here are some approaches to tracking\n",
        "memory during runtime in parallel computing environments:\n",
        "profiling tools:\n",
        "1. valgrind massif: valgrind is a powerful instrumentation framework. massif, a valgrind tool, can\n",
        "profile heap memory usage over time, showing memory consumption patterns. it's particularly\n",
        "useful for detecting memory leaks and understanding how memory usage evolves during\n",
        "program execution.\n",
        "2. intel vtune profiler : vtune profiler provides memory analysis capabilities, including memory\n",
        "usage tracking. it can analyze memory consumption at various levels, from individual functions\n",
        "to entire applications, in both serial and parallel contexts.\n",
        "3. openmp/mpi memory profiler s: many parallel programming frameworks like openmp and\n",
        "mpi provide their memory profiling tools. for example, openmp has tools like score -p, and mpi\n",
        "has memory profiling features integrated into mpi implementations.\n",
        "parallel algorithms and patterns\n",
        "a parallel algorithm is a step -by-step computational procedure or set of rules designed to be\n",
        "executed on parallel computing architectures. these algorithms are specifically crafted to take\n",
        "advantage of parallel processing capabilities, where multiple proces sors or cores can work together\n",
        "to solve a problem.\n",
        "parallel patterns are like reusable blueprints that help programmers apply proven methods to solve\n",
        "specific types of problems efficiently. these patterns guide the decomposition of tasks and data,\n",
        "providi ng a framework for creating effective parallel algorithms .\n",
        "example : parallel algorithm for finding the maximum element:\n",
        "suppose you have a large array of numbers, and you want to find the maximum element using a\n",
        "parallel algorithm based on the \"divide an d conquer\" pattern.in this example, the \"divide and\n",
        "conquer\" pattern is applied to find the maximum element in an array. the array is divided into\n",
        "smaller subarrays, and the maximum values of these subarrays are found in parallel. finally, the\n",
        "maximum amon g these partial maximums is selected as the maximum element of the entire array.\n",
        "algorithm analysis for parallel computing applications\n",
        "the goal of algorithm analysis is to compare different algorithms that are used to solve the same\n",
        "problem. one of the more traditional ways to evaluate algorithms is by looking at their algorithmic\n",
        "complexity.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMBzI2AtjrSJ"
      },
      "outputs": [],
      "source": [
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     # Set a really small chunk size, just to show.\n",
        "#    chunk_size=3096, chunk_overlap=0\n",
        "# )\n",
        "# chunks = text_splitter.split_text(text)\n",
        "# # docs = text_splitter.create_documents([text])\n",
        "# torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtiO3MJ6kt9c"
      },
      "outputs": [],
      "source": [
        "# from langchain import PromptTemplate,  LLMChain\n",
        "# def generate_summary(text_chunk):\n",
        "#     # Defining the template to generate summary\n",
        "#     template = \"\"\"\n",
        "#     Write a concise summary of the text, return your responses with 5 lines that cover the key points of the text.\n",
        "#     ```{text}```\n",
        "#     SUMMARY:\n",
        "#     \"\"\"\n",
        "#     prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "#     llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "#     summary = llm_chain.run(text_chunk)\n",
        "#     torch.cuda.empty_cache()\n",
        "#     return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tBsrAlp0k4IO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336ffb43-012e-4442-c75d-e605806c8342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: \n",
            "\"computing\" refers to the process of using computers and computer systems to perform various\n",
            "tasks, such as data processing, information storage, and solving complex problems .\n",
            "Sentence 2: this computing can be either done in serial way known as serial computing or in parallel wa y\n",
            "known as parallel computing\n",
            "serial computing:\n",
            "serial computing refers to traditional computing where tasks are executed sequentially, one after\n",
            "the other, using a single processor.\n",
            "Sentence 3: in serial computing, each instruction or task must wait for the\n",
            "previous one to complete before it can be executed.\n",
            "Sentence 4: this approach limits the speed and efficiency\n",
            "of processing, especially when dealing with complex or time -consuming tasks.\n",
            "Sentence 5: computing\n",
            "serial or\n",
            "sequential parallel example of serial computing : consider a task of sorting a large dataset of numbers in ascending\n",
            "order.\n",
            "Sentence 6: in a serial computing environment, a single processor would go through the entire dataset,\n",
            "comparing and rearranging numbers one pair at a time until the entire dataset is sorted.\n",
            "Sentence 7: this process\n",
            "occurs sequentially, and each comparison and rearrangement must wait for the previous one to\n",
            "finish.\n",
            "Sentence 8: parallel computing\n",
            "parallel computing is a type of computation in which multiple processors or computers work together\n",
            "to solve a problem.\n",
            "Sentence 9: instead of one single processor handling the entire task, parallel computing divides\n",
            "the task into smaller sub -tasks that can be processed simultaneously.\n",
            "Sentence 10: this simultaneous processing\n",
            "can lead to significant improvements in computational speed and efficien cy.\n",
            "Sentence 11: example of parallel computing: using the same example of sorting a large dataset, parallel computing\n",
            "would involve dividing the dataset into smaller chunks, and each chunk is sorted independently by a\n",
            "separate processor.\n",
            "Sentence 12: these processors work in parall el, sorting their respective chunks simultaneously.\n",
            "Sentence 13: once all processors have completed sorting their portions, the sorted chunks can be combined to\n",
            "produce the final sorted dataset.\n",
            "Sentence 14: definition parallel computing is the practice of identifying and exposing parallelism in algorithms,\n",
            "expressing this in our software, and understanding the costs, benefits, and limitations of the chosen\n",
            "implementation.\n",
            "Sentence 15: benefits of parallel computing\n",
            "\n",
            " faster run time with more compute cores: parallelization involves dividing a task into\n",
            "smaller sub -tasks that can be executed simultaneously, utilizing multiple cores to process the\n",
            "data.\n",
            "Sentence 16: this approach can significantly reduce the time required to complete the task, as each\n",
            "core works on a separate portion of the problem concurrently.\n",
            "Sentence 17:  larger problem sizes with more compute nodes : with more nodes, you can break down your\n",
            "problem into smaller pieces that each node can work on simultaneously, which is especially\n",
            "beneficial for handling larger datasets and more complex simulations .\n",
            "Sentence 18:  energy efficiency by doing more with less: in the context of parallel computing, the concept\n",
            "of \"doing more with less\" often revolves around optimizing energy efficiency while achieving\n",
            "better computational performance.this can be achieved by making use of dynamic resource\n",
            "allocation and workload consolidation to ensure that the number of processors used is\n",
            "proportional to the workload.\n",
            "Sentence 19: turn off or put to sleep any unused processors.\n",
            "Sentence 20: the energy consumption for your applicat ion can be estimated using the formula\n",
            "p = (n processors) × (r watts/processors) × (t hours)\n",
            "where p is the energy consumption, n is the number of processors, r is the thermal design\n",
            "power, and t is the application run time.\n",
            "Sentence 21:  scalability : parallel computing can be easily scaled by adding more processors, which further\n",
            "enhances performance.\n",
            "Sentence 22: serial computing does not scale in this manner, as it relies on a single\n",
            "processor.\n",
            "Sentence 23:  parallel computing can reduce costs: as technology advances, the cost of individual\n",
            "processors and memory decreases.\n",
            "Sentence 24: parallel computing systems can take advantage of these\n",
            "cost reductions, making it more economical to build high -performance computing clusters or\n",
            "data centers .\n",
            "Sentence 25: applications of parallel computing:\n",
            " scientific simulations: used in fields such as physics, chemistry, and engineering for\n",
            "complex simulations.\n",
            "Sentence 26:  big data processing: parallel computing is crucial in processing vast amounts of data in\n",
            "fields like data analytics and machine learning.\n",
            "Sentence 27:  weather forecasting: enables complex weather simulations and predictions.\n",
            "Sentence 28:  video and image processing: parallelism accelerates tasks like video rendering and\n",
            "image recognition.\n",
            "Sentence 29:  financial modelling : used for risk analysis, option pricing, and other complex financial\n",
            "calculations.\n",
            "Sentence 30: fundamental laws\n",
            "fundamental laws in parallel computing, such as amdahl's law and gustafson's law, are essential\n",
            "for understanding the limitations and possibilities of parallel processing.\n",
            "Sentence 31: these laws provide valuable\n",
            "insights into how the speedup of a parallel algorithm is affected by various factors .\n",
            "Sentence 32: what is speedup?\n",
            "Sentence 33: speedup in parallel computing refers to the performance improvement achieved by using multiple\n",
            "processors or computing resources to solve a problem compared to using a single processor.\n",
            "Sentence 34: it is a\n",
            "measure of how much faster a parallel algorithm or system can complet e a task compared to a serial\n",
            "(single -processor) implementation of the same task.\n",
            "Sentence 35: speedup is a crucial metric for evaluating the\n",
            "effectiveness of parallel computing systems.\n",
            "Sentence 36: the speedup ( s) can be calculated using the following formula:\n",
            "s=tserial / tparallel\n",
            "where:\n",
            " tserial is the execution time of the task using a single processor (serial execution time).\n",
            "Sentence 37: tparallel is the execution time of the task using multiple processors (parallel execution time).\n",
            "Sentence 38: a speedup value greater than 1 indicates that the parallel implementation is faster than the serial\n",
            "implementation.\n",
            "Sentence 39: ideally, in a perfectly parallelizable task, doubling the number of processors would ideally halve the execution time, resulting in a speedup of 2. however, achieving perfect linear\n",
            "spee dup is rare in real -world scenarios due to factors such as communication overhead, load\n",
            "balancing issues, and synchronization constraints between processors.\n",
            "Sentence 40: amdahl's law is a fundamental principle in parallel computing that expresses the potential\n",
            "speedup of a parallel algorithm as a function of the proportion of the algorithm that can be\n",
            "parallelized.\n",
            "Sentence 41: it was formulated by gene amdahl in 1967 and is represented by the fol lowing\n",
            "formula:\n",
            "where:\n",
            " speedup is the improvement in performance achieved by parallelizing a computation\n",
            "compared to executing it sequentially.\n",
            "Sentence 42:  p is the proportion of the algorithm that can be parallelized (a value between 0 and 1).\n",
            "Sentence 43:  s is the serial fraction\n",
            " n – no.of processors/nodes/cores\n",
            "amdahl's law highlights the limitations of parallel computing.\n",
            "Sentence 44: it states that the speedup of a\n",
            "program using multiple processors in parallel computing is limited by the sequential fraction of\n",
            "the program.\n",
            "Sentence 45: in other words, if only a portion of a program can be parallelized (the rest being\n",
            "inherently sequential), then no matter how many processors are added, there will always be a\n",
            "limit to the speedup that can be achieved.\n",
            "Sentence 46: for example, if 90% of a program can be parall elized (p = 0.9) and the parallel portion runs on\n",
            "5 processors , the maximum speedup that can be achieved according to amdahl's law is:\n",
            "speedup= 1/(0.1+(0.9/5))=3.57\n",
            "in this case, even though 90% of the program can be parallelized and runs on 5 processors , the\n",
            "maximum speedup achievable is approximately 3.57 times faster compared to the sequential\n",
            "execution due to the presence of the 10% sequential portion.\n",
            "Sentence 47: fig : speedup for a fixed -size problem according to amdahl’s law is shown as a function of the\n",
            "number of processors.\n",
            "Sentence 48: lines show ideal speedup when 100% of an algorithm is parallelized,\n",
            "and for 90%, 75%, and 50%.\n",
            "Sentence 49: amdahl’s law states that speedup is limited by the fractions of\n",
            "code that remain serial.\n",
            "Sentence 50: gustafson's law , formulated by john l. gustafson, provides a different perspective on parallel\n",
            "computing compared to amdahl's law.\n",
            "Sentence 51: unlike amdahl's law, which focuses on fixed problem sizes,\n",
            "gustafson's law takes into account varying problem sizes.\n",
            "Sentence 52: the basic idea behind g ustafson's law is\n",
            "that as the size of the problem increases, the impact of the parallelizable portion of the program\n",
            "becomes more significant, leading to better scalability.\n",
            "Sentence 53: in other words, with larger problem sizes,\n",
            "parallel systems can achieve higher lev els of speedup.\n",
            "Sentence 54: the formula for gustafson's law is as follows:\n",
            "speedup(n) = n – s * (n – 1) where n is the number of processors, and s is the serial fraction\n",
            "strong scaling and weak scaling are two different m etrics used to evaluate the performance of\n",
            "parallel computing systems, and they provide insights into how well a parallel algorithm or\n",
            "application can handle an increasing workload or an increasing number of processors.\n",
            "Sentence 55: here's a\n",
            "comparison of strong scalin g and weak scaling:\n",
            "strong scaling:\n",
            "definition: strong scaling measures how the execution time of a fixed problem size decreases\n",
            "as the number of processors increases.\n",
            "Sentence 56: in other words, it assesses how well a parallel system\n",
            "performs when the size of the problem remains constant, but the number of proces sors used\n",
            "to solve the problem increases.\n",
            "Sentence 57: objective: the goal of strong scaling is to reduce the execution time for a fixed problem size by\n",
            "utilizing more processors.\n",
            "Sentence 58: it aims to speed up the solution of a specific problem.\n",
            "Sentence 59: scenario: strong scaling is applicable when the size of the problem is fixed, and the aim is to\n",
            "solve that problem faster by employing additional processors.\n",
            "Sentence 60: 2. weak scaling:\n",
            "definition: weak scaling measures how the execution time changes as both the problem size\n",
            "and the number of processors increase proportionally.\n",
            "Sentence 61: in other words, it assesses how well a\n",
            "parallel system can handle larger workloads by adding more processors as the problem size\n",
            "grows.\n",
            "Sentence 62: objective: the goal of weak scaling is to maintain a constant workload per processor as the size\n",
            "of the problem and the number of processors increase.\n",
            "Sentence 63: it aims to solve larger problems in\n",
            "approximately the same amount of time per processor.\n",
            "Sentence 64: scenario: weak scaling is applicable when the problem size can be increased, and the aim is to\n",
            "handle larger workloads by distributing the computational load across a larger number of\n",
            "processors.\n",
            "Sentence 65: parallel approaches (flynn’s classification)\n",
            "\n",
            "flynn's classification is essential in the field of parallel computing because it provides a framework\n",
            "for understanding and categorizing different types of computer architectures based on the number\n",
            "of instruction streams and data streams.\n",
            "Sentence 66: this classifica tion is named after michael j. flynn, who\n",
            "introduced it in 1966. flynn’s taxonomy is a useful tool for understanding different types of\n",
            "computer architectures and their strengths and weaknesses.\n",
            "Sentence 67: the taxonomy highlights the importance of parallelism in modern computing and shows how\n",
            "different types of parallelism can be exploited to improve performance.\n",
            "Sentence 68: it helps in designing and\n",
            "analyzing parallel processing systems\n",
            "\n",
            "1. single instruction single data (sisd ): in a sisd architecture, there is a single processor\n",
            "that executes a single instruction stream and operates on a single data stream.\n",
            "Sentence 69: this is the\n",
            "simplest type of computer architecture and is used in most traditional computers.\n",
            "Sentence 70: 2. single instruction multiple data (simd ): in a simd architecture, there is a single\n",
            "processor that executes the same instruction on multiple data streams in parallel.\n",
            "Sentence 71: this type of\n",
            "architecture is used in applications such as image and signal processing.\n",
            "Sentence 72: 3. multiple instruction single data (misd ): in a misd architecture, multiple processors\n",
            "execute different instructions on the same data stream.\n",
            "Sentence 73: this type of architecture is not\n",
            "commonly used in practice, as it is difficult to find applications that can be decomposed into\n",
            "indepen dent instruction streams.\n",
            "Sentence 74: 4. multiple instruction multiple data (mimd ): in a mimd architecture, multiple processors\n",
            "execute different instructions on different data streams.\n",
            "Sentence 75: this type of architecture is used in\n",
            "distributed computing, parallel processing, and other high -performance computing applications.\n",
            "Sentence 76: parallel strategies\n",
            "parallel strategies\" typically refer to techniques and methods for parallel processing, which is the\n",
            "simultaneous execution of multiple tasks or processes to improve the efficiency and performance\n",
            "of a computer system.\n",
            "Sentence 77: parallel strategies are commonly used in various computing domains, such\n",
            "as high -performance computing and distributed systems, to speed up computations and handle\n",
            "large volumes of data.\n",
            "Sentence 78: here are some common parallel s trategies:\n",
            "data parallel approach\n",
            "data parallelism involves performing the same operation on multiple data elements simultaneously.\n",
            "Sentence 79: this strategy is often used in applications where the same operation can be applied to different\n",
            "pieces of data independent ly.\n",
            "Sentence 80: scenario : imagine you're running a data analysis task on a large dataset of customer reviews for a\n",
            "product.\n",
            "Sentence 81: your goal is to perform sentiment analysis on each review to determine if it's positive,\n",
            "negative, or neutral.\n",
            "Sentence 82: the sentiment analysis process is computationally intensive, and you want to\n",
            "speed it up using data parallelism.\n",
            "Sentence 83: data parallelism in sentiment analysis :\n",
            "1. data preparation : you have a dataset of 1,000,000 customer reviews.\n",
            "Sentence 84: to apply data\n",
            "parallelism, you divide this dataset into smaller, non-overlapping subsets.\n",
            "Sentence 85: let's say you split\n",
            "it into four subsets, each containing 250,000 reviews.\n",
            "Sentence 86: 2. parallel processing : you have a sentiment analysis model that can analyze reviews.\n",
            "Sentence 87: you set\n",
            "up four separate processing units (e.g., cpu cores or machines in a cluster), each responsible\n",
            "for analyzing one subset of reviews.\n",
            "Sentence 88: each processing unit loads its assigned subset of data.\n",
            "Sentence 89: 3. analysis : each processing unit applies the sentiment analysis model to its subset of reviews\n",
            "independently and simultaneously.\n",
            "Sentence 90: for in stance:\n",
            " processing unit 1 analyzes reviews 1 to 250,000.\n",
            "Sentence 91:  processing unit 2 analyzes reviews 250,001 to 500,000.\n",
            "Sentence 92:  processing unit 3 analyzes reviews 500,001 to 750,000.\n",
            "Sentence 93:  processing unit 4 analyzes reviews 750,001 to 1,000,000.\n",
            "Sentence 94: 4. aggregation : as each processing unit finishes its analysis, it generates results, such as counts\n",
            "of positive, negative, and neutral reviews within its subset.\n",
            "Sentence 95: these results are temporarily\n",
            "stored.\n",
            "Sentence 96: 5. combining results : after all processing units have completed their work, you combine the\n",
            "results.\n",
            "Sentence 97: you sum up the counts from each processing unit to get the overall sentiment\n",
            "analysis results for the entire dataset.\n",
            "Sentence 98: task parallelism(main -worker approach)\n",
            "task parallelism involves executing multiple independent tasks or processes in parallel.\n",
            "Sentence 99: each task\n",
            "can perform different operations and may not necessarily operate on the same data.\n",
            "Sentence 100: task\n",
            "parallelism is common in applications where different tasks can be performed concurrently without\n",
            "dependencies between them.\n",
            "Sentence 101: in the main -worker approach, one processor schedules and distributes the tasks for all the workers,\n",
            "and each worker checks for the next work item as it returns the previous completed task .\n",
            "Sentence 102: example: web server handling requests\n",
            "consider a web server handling incoming http requests.\n",
            "Sentence 103: each i ncoming request is an independent\n",
            "task that can be processed concurrently.\n",
            "Sentence 104: the tasks include tasks like parsing the request, querying\n",
            "the database, and generating the response.\n",
            "Sentence 105: in a task parallelism scenario:\n",
            "1. task 1: parsing request\n",
            " this task involves pars ing the incoming http request to extract information like the\n",
            "requested url, parameters, and headers.\n",
            "Sentence 106: 2. task 2: database query\n",
            " this task involves querying a database to fetch data related to the request, such as\n",
            "user information or product details.\n",
            "Sentence 107: 3. task 3: generating response\n",
            " this task involves generating an html response based on the parsed request and\n",
            "data retrieved from the database.\n",
            "Sentence 108: in a task parallelism setup, these tasks can be executed concurrently by multiple threads or\n",
            "processes, allowing the server to handle multiple incoming requests simultaneously without waiting\n",
            "for one task to complete before starting the next.\n",
            "Sentence 109: bucket -brigade parallelism :\n",
            "a bucket brigade is a method of manually transporting items or materials from one location to\n",
            "another by forming a line of people, each of whom carries an item and passes it to the next person.\n",
            "Sentence 110: this technique is similar to how buckets of water might be passed along a line of people to put out a\n",
            "fire, which is where the term \"bucket brigade\" originated.\n",
            "Sentence 111: in parallel computing, the concept of bucket -brigade parallelism involves breaking down a task into\n",
            "smaller subtasks, where each subtask is processed independently and passed to the next processing\n",
            "unit for further computation.\n",
            "Sentence 112: this technique allows for efficient parallel processing of tasks and is\n",
            "often used in scenarios where tasks can be divided into smaller, manageable parts.\n",
            "Sentence 113: example: manufacturing assembly line\n",
            "let's say we have a manufacturing assembly line for producing smartphones.\n",
            "Sentence 114: the assembly line\n",
            "consists of three stages: a, b, and c. each stage represents a specific task in the smartphone\n",
            "assembly process.\n",
            "Sentence 115: 1. stage a - component assembly :\n",
            " worker a assembles the basic components of the smartphone, such as the circuit\n",
            "board, battery, and display.\n",
            "Sentence 116: once worker a finishes assembling a smartphone, it passes it\n",
            "to stage b.\n",
            "Sentence 117: 2. stage b - software installation :\n",
            " worker b installs the operating system and necessary software onto the smartphone\n",
            "assembled by worker a. after software installation, the smartphone is passed to stage c.\n",
            "3. stage c - quality control and packaging :\n",
            " worker c checks the smartphone for quality control, ensuring that all components\n",
            "are working correctly an d the software is functioning as intended.\n",
            "Sentence 118: if the smartphone passes\n",
            "quality control, it is packaged and prepared for shipment.\n",
            "Sentence 119: in this example, each stage (a, b, and c) represents a processing step, similar to the stages in a\n",
            "bucket -brigade parallelism sce nario.\n",
            "Sentence 120: parallel speedup versus comparative speedups.\n",
            "Sentence 121: parallel speedup and comparative speedup are two different metrics used to evaluate the performance\n",
            "improvement achieved by parallel processing.\n",
            "Sentence 122: parallel speedup measures how much faster a parallel algorithm runs compared to its sequential\n",
            "(single -processor) counterpart.\n",
            "Sentence 123: it quantifies the performance improvement gained by using multiple\n",
            "processing units in parallel.\n",
            "Sentence 124: parallel speedup is calculated using the followi ng formula:\n",
            "parallel speedup=sequential execution time/parallel execution\n",
            "in this formula:\n",
            " sequential execution time is the time taken by the algorithm to execute sequentially on a\n",
            "single processor.\n",
            "Sentence 125:  parallel execution time is the time taken by the paralle l algorithm to execute on multiple\n",
            "processors.\n",
            "Sentence 126: comparative speedup : comparative speedup is between architectures.\n",
            "Sentence 127: this is usually a\n",
            "performance comparison between two parallel implementations or other comparison between\n",
            "reasonably constrained sets of hardware.\n",
            "Sentence 128: for example, it may be between a parallel mpi\n",
            "implementation on all the cores of the node of a computer versus the gpu(s) on a node\n",
            "how parallel computing works\n",
            "as a developer, you are responsible for the application software layer, which includes your source code.\n",
            "Sentence 129: in the source code, you make choices about the programming language and parallel software interfaces\n",
            "you use to leverage the underlying hardware.\n",
            "Sentence 130: additionally, you decide how to break up your work into\n",
            "parallel units.\n",
            "Sentence 131: a compiler is designed to translate your source code into a form the hardware can execute.\n",
            "Sentence 132: with these instructions at hand, an os manages executing these on the computer hardware.\n",
            "Sentence 133: parallel approach models are used to express parallelization in an application software layer\n",
            "that gets mapped to the computer hardware through the compiler and the os.\n",
            "Sentence 134: parallel computing\n",
            "approaches involve various models and paradigms that define how tasks are divided, coordinated, and\n",
            "executed in parallel systems.\n",
            "Sentence 135: here are some common parallel computing approach models:\n",
            "hardware models\n",
            "distributed memory architecture: a cross -node parallel method :\n",
            "parallel approach models\n",
            "hardware models\n",
            "distributed memory architecture:\n",
            "a cross -node parallel method :\n",
            "shared memory architecture: an\n",
            "on-node parallel method\n",
            "vector units: multiple operations\n",
            "with one instruction\n",
            "accelerator device: a special -\n",
            "purpose add-on processor\n",
            "software models\n",
            "process -based parallelization :\n",
            "message passing\n",
            "thread -based parallelization :\n",
            "shared data via memory\n",
            "vectorization : multiple\n",
            "operations with one instruction\n",
            "stream processing : through\n",
            "specialized processors\n",
            "distributed memory architecture, also known as distributed memory parallelism, is a parallel\n",
            "computing method where multiple processors or nodes in a cluster have their own private memory.\n",
            "Sentence 136: these nodes are connected via a network, and they communicate and coordinate with each other\n",
            "by passing messages.\n",
            "Sentence 137: in this architecture, each node opera tes independently and has its own local\n",
            "memory, and data sharing is achieved explicitly through message passing.\n",
            "Sentence 138: in the context of distributed memory architecture, a \"cross -node parallel method\" refers to parallel\n",
            "processing techniques that involve distributing tasks across multiple nodes in a cluster.\n",
            "Sentence 139: each node\n",
            "works on its subset of the data or a specific portion of the computation.\n",
            "Sentence 140: communication and\n",
            "coordination between nodes are essential, as tasks often depend on results or data computed on\n",
            "othe r nodes.\n",
            "Sentence 141: shared memory architecture: an on-node parallel method\n",
            "in shared memory architecture, multiple processors or cores share a single, unified memory space.\n",
            "Sentence 142: this shared memory can be accessed and modified by any processor within the system.\n",
            "Sentence 143: on -node\n",
            "parallelism, within the context of shared memory architecture, ref ers to parallel processing\n",
            "techniques that occur on a single computing node.\n",
            "Sentence 144: in this approach, multiple threads or processes\n",
            "run concurrently on the same node, accessing shared memory to perform computations .\n",
            "Sentence 145: vector units: multiple operations with one instruction\n",
            "vector units, also known as vector processors, are specialized hardware units that can perform\n",
            "multiple operations with a single instruction.\n",
            "Sentence 146: these units are designed to process vectors, which are\n",
            "arrays of data elements, simultaneously.\n",
            "Sentence 147: vecto r processing is particularly useful in scenarios where\n",
            "the same operation needs to be performed on a large set of data elements .\n",
            "Sentence 148: vector processing example with four array elements operated on simultaneously\n",
            "accelerator device: a special -purpose add-on processor\n",
            "gpus come in two varieties: integrated and discrete.\n",
            "Sentence 149: discrete or dedicated gpus typically have a\n",
            "large number of streaming multiprocessors and their own dram.\n",
            "Sentence 150: accessing data on a discrete gpu\n",
            "requires communication over a pci bus\n",
            "an accelerator device, often referred to as an accelerator, is a specialized hardware component\n",
            "(gpu) designed to perform specific types of computational tasks or workloads efficiently.\n",
            "Sentence 151: accelerators are typically used in conjunction with a central processin g unit (cpu) and are especially\n",
            "well-suited for workloads that can benefit from parallel processing and offloading certain tasks from\n",
            "the cpu.\n",
            "Sentence 152: accelerators are sometimes called \"add -on processors\" because they augment the\n",
            "processing capabilities of a syste m.\n",
            "general heterogeneous parallel architecture model\n",
            "now let’s combine all of these different hardware architectures into one model .\n",
            "Sentence 153: two nodes, each\n",
            "with two cpus, share the same dram memory.\n",
            "Sentence 154: each cpu is a dual -core processor with an\n",
            "integrated gpu.\n",
            "Sentence 155: a discrete gpu on the pci bus also attaches to one of the cpus.\n",
            "Sentence 156: though the cpus\n",
            "share main memory, these are commonly in different non -uniform memory access (numa)\n",
            "regions.\n",
            "Sentence 157: this means that accessing the second cpu’s memory is more expensive than getting at it’s\n",
            "own memory\n",
            "fig 5: a general heterogeneous parallel architecture model consisting of two nodes connected by\n",
            "a network.\n",
            "Sentence 158: each node has a multi -core cpu with an integrated and discrete gpu and some\n",
            "memory (dram).\n",
            "Sentence 159: software models\n",
            "the programmer must first expose the parallelization, determine the best technique to operate in\n",
            "parallel, and then explicitly direct its operation in a safe, correct, and efficient manner.\n",
            "Sentence 160: the following\n",
            "methods are the most common techniques for parallelization\n",
            " process -based parallelization : message passing\n",
            "process -based parallelization, particularly through message passing, is a common approach in\n",
            "parallel computing.\n",
            "Sentence 161: it involves dividing a task into multiple processes or threads that run\n",
            "independently on separate computing nodes or cores.\n",
            "Sentence 162: these processes communicate and\n",
            "coordinate with each other by sending and receiving messages.\n",
            "Sentence 163: message passing is a method of\n",
            "inter -process communication where data and instructions are exchanged between processes to\n",
            "synch ronize and share information.\n",
            "Sentence 164: this approach is widely used in distributed memory systems,\n",
            "such as clusters and supercomputers.\n",
            "Sentence 165: fig 6 : the message passing library spawns processes.\n",
            "Sentence 166: the os places the processes on the cores\n",
            "of two nodes.\n",
            "Sentence 167: the question marks i ndicate that the os controls the placement of the processes\n",
            "and can move these during run time as indicated by the dashed arrows.\n",
            "Sentence 168: the os also allocates\n",
            "memory for each process from the node’s main memory\n",
            " thread -based parallelization : shared data via memory\n",
            "thread -based parallelization involves dividing a task into multiple threads that share the same\n",
            "memory space within a single process.\n",
            "Sentence 169: these threads can run concurrently on multiple cpu cores,\n",
            "and they communicate and coordinate by accessing shared data in the shared memory.\n",
            "Sentence 170: this\n",
            "approach is commonly used in multi -core processors and symmetric multiprocessing (smp) systems.\n",
            "Sentence 171: fig 7: the application process in a thread -based approach to parallelization spawns\n",
            "threads.\n",
            "Sentence 172: the threads are restricted to the node’s domain.\n",
            "Sentence 173: the question marks show that\n",
            "the os decides where to place the threads.\n",
            "Sentence 174: some memory is shared between threads.\n",
            "Sentence 175:  vectorization : multiple operations with one instruction\n",
            "vectorization is a parallel computing technique that enables processors to perform multiple\n",
            "operations with a single instruction.\n",
            "Sentence 176: it takes advantage of simd (single instruction, multiple data)\n",
            "capabilities found in modern processors, including cpus and gpus.\n",
            "Sentence 177: simd allows a single instruction\n",
            "to operate on multiple da ta elements simultaneously, which can significantly accelerate\n",
            "computations involving large datasets.\n",
            "Sentence 178:  stream processing : through specialized processors\n",
            "stream processing, often referred to as stream computing or data stream processing, is a computing\n",
            "paradigm where data is continuously processed as it is generated or ingested, rather than being\n",
            "stored in traditional databases or file systems.\n",
            "Sentence 179: stream proce ssing is particularly useful for handling\n",
            "large volumes of real -time data from various sources, such as sensors, social media, financial\n",
            "transactions, and iot devices.\n",
            "Sentence 180: specialized processors designed for stream processing accelerate the\n",
            "analysis and manipu lation of data streams, ensuring timely and efficient processing\n",
            "in the stream processing approach, data and compute kernel are offloaded to the gpu and its\n",
            "streaming multiprocessors.\n",
            "Sentence 181: processed data, or output, transfers back to the cpu for file io or other\n",
            "work\n",
            "sample application\n",
            "we start with a 2d problem domain of a region of space.\n",
            "Sentence 182: for purposes of illustration, we will use\n",
            "a 2d image of the krakatau volcano as our example.\n",
            "Sentence 183: the goal of our calculation could be to model\n",
            "the volcanic plume, the resulting tsunami, or the early detection of a volcanic eruption using\n",
            "machine learning.\n",
            "Sentence 184: for all of these options, calculation speed is critical if we want real -time result s\n",
            "to inform our decisions.\n",
            "Sentence 185: 1. discretize (break up) the problem into smaller cells or elements\n",
            "2 .\n",
            "Sentence 186: define a computational kernel (operation) to conduct on each element of the mesh\n",
            "3. add the following layers of parallelization on cpus and gpus to perfo rm the calculation:\n",
            "vectorization —work on more than one unit of data at a time\n",
            "4. threads —deploy more than one compute pathway to engage more processing cores\n",
            "5. processes —separate program instances to spread out the calculation into separate memory\n",
            "spaces\n",
            "6. off -loading the calculation to gpus —send the data to the graphics processor to calculate\n",
            "step 1: discretize the problem into smaller cells or elements\n",
            "the domain is discretized into cells.\n",
            "Sentence 187: for each cell in the computational domain, properties such as\n",
            "wave height, fluid velocity, or smoke density are solved for according to physical laws.\n",
            "Sentence 188: ultimately, a\n",
            "stencil operation or a matrix -vector system represents this discrete scheme\n",
            "step 2: define a computational kernel, or operation, to conduct on each element of the mesh\n",
            "the calculations on this discretized data are often some form of a stencil operation, so -called because\n",
            "it involves a pattern of a djacent cells to calculate the new value for each cell.\n",
            "Sentence 189: this can be an average\n",
            "(a blur operation, which blurs the image )gradient (edge -detection, which sharpens the edges in the\n",
            "image) or another more complex operation associated with solving physical sys tems described by\n",
            "partial differential equations (pdes)\n",
            "step 3: vectorization to work on more than one unit of data at a time\n",
            "some processors have the ability to operate on more than one piece of data at a time; a capability\n",
            "referred to as vector operations.\n",
            "Sentence 190: the shaded blocks in figure illustrate how multiple data values\n",
            "are operated on simultaneously in a vector unit in a proce ssor with one instruction in one clock\n",
            "cycle.\n",
            "Sentence 191: step 4: threads to deploy more than one compute pathway to engage more processing cores\n",
            "because most cpus today have at least four processing cores, we use threading to operate the cores\n",
            "simultaneously acros s four rows at a time.\n",
            "Sentence 192: step 5: processes to spread out the calculation to separate memory spaces\n",
            "we can further split the work between processors on two desktops, often called nodes in parallel\n",
            "processing.\n",
            "Sentence 193: when the work is split across nodes, the memory spaces for each node are distinct and\n",
            "separate.\n",
            "Sentence 194: step 6: off -loading the calculation to gpus\n",
            "on a gpu, the vector length is much larger than on a cpu.\n",
            "Sentence 195: here, 8×8 tiles are distributed across\n",
            "gpu work groups.\n",
            "Sentence 196: performance limits and profiling\n",
            "in parallel processing, understanding performance limits and profiling the application are crucial\n",
            "steps to optimize the execution of parallel programs.\n",
            "Sentence 197: performance limits refer to the maximum achievable performance of a computing system or\n",
            "application un der specific conditions.\n",
            "Sentence 198: these limits are determined by various factors and constraints\n",
            "and play a crucial role in understanding the capabilities and limitations of a system.\n",
            "Sentence 199: understanding\n",
            "these performance limits is essential for designing efficient algor ithms, optimizing software, and\n",
            "choosing appropriate hardware configurations.\n",
            "Sentence 200: it also guides researchers and engineers in\n",
            "developing new technologies to overcome existing limitations and improve overall computing\n",
            "performance.\n",
            "Sentence 201: profiling tools are used to ga ther detailed information about the behavior of a parallel program.\n",
            "Sentence 202: by\n",
            "understanding performance limits, utilizing profiling tools, and optimizing the code based on the\n",
            "profiling results, developers can enhance the efficiency of parallel applications, lea ding to improved\n",
            "speedup and overall performance.\n",
            "Sentence 203: application’s potential performance limits\n",
            " flops (floating -point operations)\n",
            " ops (operations) that include all types of computer instructions\n",
            " memory bandwidth: rate at which the data is transferred\n",
            " memory latency: time required for the first byte or word of data to be transferred\n",
            " instruction queue (instruction cache)\n",
            " networks\n",
            " disk\n",
            " machine balance: number of flops executed /memory bandwidth\n",
            " arithmetic intensity : number of flops executed per memory operation\n",
            "all of these limitations can be divided into two major categories:.\n",
            "Sentence 204: speeds are how fast operations can\n",
            "be done.\n",
            "Sentence 205: it includes all types of computer operations.\n",
            "Sentence 206: but to be able to do the operations, you must\n",
            "get the data there.\n",
            "Sentence 207: this is where feeds come in.\n",
            "Sentence 208: feeds include the memory bandwidth through the\n",
            "cache hierarchy, as well as network and disk bandwidth .\n",
            "Sentence 209: for many applications, the memory bandwidth limit can be difficult especially dealing with non-\n",
            "contiguous bandwidth.it is also known as strided memory access or non -contiguous memory\n",
            "access, refers to the manner in which data elements are accessed in memory.\n",
            "Sentence 210: in contrast to\n",
            "contiguous memory access, where elements are stored in consecutive memory locations, non -\n",
            "contiguous memory access invo lves accessing elements that are not stored sequentially in memory.\n",
            "Sentence 211: non -contiguous memory access:\n",
            "now, consider a situation where the array elements are scattered in memory with a stride of 2. this\n",
            "is a non -contiguous memory access pattern:\n",
            "in this case, accessing every second element (stride = 2) would mean accessing memory locations 1,\n",
            "2, 3, 4, 5, etc., but the elements are not stored sequentially.\n",
            "Sentence 212: when your program needs to access such non -contiguous elements, it may lead to inefficiencie s\n",
            "due to increased cache misses and a higher likelihood of accessing data from main memory rather\n",
            "than the faster cache memory.\n",
            "Sentence 213: determine your hardware capabilities:\n",
            "to determine the performance of hardware the following metrics are used :\n",
            " the rate at which floating -point operations can be executed (flops/s)\n",
            " the rate at which data can be moved between various levels of memory (gb/s)\n",
            " the rate at which energy is used by your application (watts)\n",
            "in determining hardware performance and calculating the metrics , we use a mixture of theoretical\n",
            "and empirical measurements .\n",
            "Sentence 214: theoretical measurements provide an upper limit to what a system can achieve.\n",
            "Sentence 215: for instance, in\n",
            "parallel computing, theoretical analysis can reveal the maximum speedup or efficiency that a\n",
            "parallel algorithm can achieve in an ideal scenario .\n",
            "Sentence 216: real -world validation is done by empirical measurements , they provide concrete evidence of how\n",
            "a system performs under real -world conditions, accounting for various factors like i/o operations,\n",
            "network latency, and concurrency issues.\n",
            "Sentence 217: one of the best tools for understanding the hardware you run is the lstopo program (graphical view)\n",
            "and lscpu for text view .\n",
            "Sentence 218: lstopo is bundled with the hwloc package that com es with nearly every mpi\n",
            "distribution.\n",
            "Sentence 219: this command outputs a graphical view of the hardware on your system.\n",
            "Sentence 220: figure below\n",
            "shows the output for a mac laptop in graphical view.\n",
            "Sentence 221: text view\n",
            "the information from the lscpu command and the /proc/cpuinfo file helps to determine the number\n",
            "of processors, the processor model, the cache sizes, and the clock frequency for the system\n",
            "calculating theoretical maximum flops\n",
            "theoretical flops=number of cores×clock speed×flops per cycle per core\n",
            "where:\n",
            " number of cores: this represents the total number of processor cores in the computing\n",
            "system.\n",
            "Sentence 222:  clock speed: this indicates the clock speed of each core in the system, typically measured\n",
            "in hertz (hz) or gigahertz (ghz).\n",
            "Sentence 223: it represents the number of cycles th e processor can\n",
            "execute per second.\n",
            "Sentence 224:  flops per cycle per core: this signifies the number of floating -point operations a core can\n",
            "perform in a single clock cycle.\n",
            "Sentence 225: modern processors often perform multiple flops per cycle\n",
            "due to features like simd (single inst ruction, multiple data) operations.\n",
            "Sentence 226: for example, let's consider a system with 4 cores, each operating at 3.0 ghz, and capable of\n",
            "executing 4 flops per cycle per core (assuming simd operations are utilized):\n",
            "theoretical flops=4 cores×3.0 ghz×4 flops per cycle per core\n",
            "theoretical flops=48 gflops\n",
            "the memory hierarchy and theoretical memory bandwidth\n",
            "we can calculate the theoretical memory bandwidth of the main memory using the memory chips\n",
            "specifications.\n",
            "Sentence 227: the general formula is b t = mtr × mc × tw × ns = data transfer rate × memory channels × bytes\n",
            "per access × sockets\n",
            "processors are installed in a socket on the motherboard.\n",
            "Sentence 228: the motherboard is the main system board\n",
            "of the computer, and the socket is the lo cation where the processor is inserted.\n",
            "Sentence 229: most motherboards\n",
            "are single -socket, where only one processor can be installed.\n",
            "Sentence 230: dual -socket motherboards are more\n",
            "common in high -performance computing systems.\n",
            "Sentence 231: two processors can be installed in a dual -socket\n",
            "motherb oard, giving us more processing cores and more memory bandwidth.\n",
            "Sentence 232: empirical measurement of bandwidth and flop\n",
            "the empirical bandwidth is the measurement of the fastest rate that memory can be loaded from\n",
            "main memory into the processor.\n",
            "Sentence 233: if a single byte of m emory is requested, it takes 1 cycle to retrieve\n",
            "it from a cpu register.\n",
            "Sentence 234: if it is not in the cpu register, it comes from the l1 cache.\n",
            "Sentence 235: if it is not in the l1\n",
            "cache, the l1 cache loads it from l2 and so on to main memory.\n",
            "Sentence 236: if it goes all the way to main\n",
            "memo ry, for a single byte of memory, it can take around 400 clock cycles.\n",
            "Sentence 237: this time required for the\n",
            "first byte of data from each level of memory is called the memory latency .\n",
            "Sentence 238: two different methods are used for measuring the bandwidth: the stream benchmark and the\n",
            "roofline model measured by the empirical roofline toolkit.\n",
            "Sentence 239: key differences:\n",
            " focus: stream primarily focuses on memory bandwidth, providing quantitative\n",
            "measurements.\n",
            "Sentence 240: in contrast, the roofline model provides a graphical representation of\n",
            "performance bottlenecks, considering both computational capabilities and memory\n",
            "bandwidth.\n",
            "Sentence 241:  representation: stream results in a numerical measurement (memory bandwidth in bytes\n",
            "per second), while the roofline model is a graphical representation that helps v isualize\n",
            "performance limitations.\n",
            "Sentence 242:  insights: stream provides detailed insights into memory subsystem performance, whereas\n",
            "the roofline model offers a high -level overview of an application's performance efficiency\n",
            "concerning hardware constraints.\n",
            "Sentence 243: calculatin g the machine balance between flops and bandwidth\n",
            "the machine balance is the flops divided by the memory bandwidth.\n",
            "Sentence 244: we can calculate both a theoretical machine balance (mb t) and an empirical machine balance (mb e)\n",
            "like so:\n",
            "mb t = f t / b t\n",
            "mb e = f e / b e\n",
            "characterizing your application: profiling\n",
            "now that you have some sense of what performance you can get with the hardware, you need to\n",
            "determine what are the performance characteristics of your application.\n",
            "Sentence 245: additionally, you should\n",
            "develop an understandi ng of how different subroutines and functions depend on each other .\n",
            "Sentence 246: profiling tools :\n",
            "using call graphs for hot -spot and dependency analysis\n",
            "in the context of parallel programming, call graphs are diagrams that represent the calling\n",
            "relationships between different functions or methods in a parallel program.\n",
            "Sentence 247: they illustrate how\n",
            "functions or tasks invoke each other and provide a visual representation of the program's control\n",
            "flow.\n",
            "Sentence 248: analyzing call graphs in parallel programming can provide valuable insights in to the program's\n",
            "structure, dependencies, and potential performance optimizations .\n",
            "Sentence 249: by analyzing these call graphs,\n",
            "developers can identify hot -spots —functions or tasks that consume a significant amount of\n",
            "computational time.\n",
            "Sentence 250: optimizing these hot -spots is e ssential for improving overall parallel program\n",
            "performance.\n",
            "Sentence 251: empirical measurement of processor clock frequency and energy consumption\n",
            "empirical measurement of processor clock frequency:\n",
            "1. profiling tools: profiling tools like intel vtune profiler or amd codexl can provide insights\n",
            "into various performance metrics, including processor clock frequency.\n",
            "Sentence 252: these tools often offer\n",
            "visualizations and detailed reports for better analysis.\n",
            "Sentence 253: 2. benchmarking suites: benchmarking tools like spec cpu benchmarks or hpc chal lenge\n",
            "benchmarks often include components that measure processor clock frequencies.\n",
            "Sentence 254: running\n",
            "these benchmarks can provide detailed information about the processor's performance\n",
            "characteristics.\n",
            "Sentence 255: 2. empirical measurement of energy consumption:\n",
            "1. power measureme nt tools: use power measurement tools and hardware devices to\n",
            "measure the power consumption of your system.\n",
            "Sentence 256: power meters and sensors can be attached\n",
            "to the system to measure real -time power usage.\n",
            "Sentence 257: tools like intel power gadget or linux's\n",
            "powerstat can help measure power usage.\n",
            "Sentence 258: 2. energy profilers: some profiling tools, like intel vtune profiler, also offer energy profiling\n",
            "capabilities.\n",
            "Sentence 259: they can provide insights into energy consumption patterns at different parts of\n",
            "your code.\n",
            "Sentence 260: these tools often correlate energ y consumption with specific functions or code\n",
            "regions.\n",
            "Sentence 261: tracking memory during run time\n",
            "tracking memory usage during runtime in parallel computing is crucial for optimizing performance,\n",
            "detecting memory leaks, and ensuring efficient memory management.\n",
            "Sentence 262: several techniques and tools\n",
            "can help you monitor memory usage in parallel applications.\n",
            "Sentence 263: here are some approaches to tracking\n",
            "memory during runtime in parallel computing environments:\n",
            "profiling tools:\n",
            "1. valgrind massif: valgrind is a powerful instrumentation framework.\n",
            "Sentence 264: massif, a valgrind tool, can\n",
            "profile heap memory usage over time, showing memory consumption patterns.\n",
            "Sentence 265: it's particularly\n",
            "useful for detecting memory leaks and understanding how memory usage evolves during\n",
            "program execution.\n",
            "Sentence 266: 2. intel vtune profiler : vtune profiler provides memory analysis capabilities, including memory\n",
            "usage tracking.\n",
            "Sentence 267: it can analyze memory consumption at various levels, from individual functions\n",
            "to entire applications, in both serial and parallel contexts.\n",
            "Sentence 268: 3. openmp/mpi memory profiler s: many parallel programming frameworks like openmp and\n",
            "mpi provide their memory profiling tools.\n",
            "Sentence 269: for example, openmp has tools like score -p, and mpi\n",
            "has memory profiling features integrated into mpi implementations.\n",
            "Sentence 270: parallel algorithms and patterns\n",
            "a parallel algorithm is a step -by-step computational procedure or set of rules designed to be\n",
            "executed on parallel computing architectures.\n",
            "Sentence 271: these algorithms are specifically crafted to take\n",
            "advantage of parallel processing capabilities, where multiple proces sors or cores can work together\n",
            "to solve a problem.\n",
            "Sentence 272: parallel patterns are like reusable blueprints that help programmers apply proven methods to solve\n",
            "specific types of problems efficiently.\n",
            "Sentence 273: these patterns guide the decomposition of tasks and data,\n",
            "providi ng a framework for creating effective parallel algorithms .\n",
            "Sentence 274: example : parallel algorithm for finding the maximum element:\n",
            "suppose you have a large array of numbers, and you want to find the maximum element using a\n",
            "parallel algorithm based on the \"divide an d conquer\" pattern.in this example, the \"divide and\n",
            "conquer\" pattern is applied to find the maximum element in an array.\n",
            "Sentence 275: the array is divided into\n",
            "smaller subarrays, and the maximum values of these subarrays are found in parallel.\n",
            "Sentence 276: finally, the\n",
            "maximum amon g these partial maximums is selected as the maximum element of the entire array.\n",
            "Sentence 277: algorithm analysis for parallel computing applications\n",
            "the goal of algorithm analysis is to compare different algorithms that are used to solve the same\n",
            "problem.\n",
            "Sentence 278: one of the more traditional ways to evaluate algorithms is by looking at their algorithmic\n",
            "complexity.\n"
          ]
        }
      ],
      "source": [
        "def paragraph_to_sentences(paragraph):\n",
        "    # Using the nltk library for sentence tokenization\n",
        "    import nltk\n",
        "    nltk.download('punkt')  # Download the punkt tokenizer if not already downloaded\n",
        "\n",
        "    # Tokenize the paragraph into sentences\n",
        "    sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Example usage\n",
        "sentences_list = paragraph_to_sentences(text)\n",
        "\n",
        "# Print the list of sentences\n",
        "for idx, sentence in enumerate(sentences_list, start=1):\n",
        "    print(f\"Sentence {idx}: {sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tkxhz3Xhk52F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d461f45-3386-47c0-f417-754124bfbad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61.4/86.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=9e1fb2f71591da692948bf29130c5c5bd903575085a9dafe76e20c305b47ccff\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5IBSRnjV1eJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "a8fa5c315a964fa085e1a62f7848b7dc",
            "510d04c062af4848b701e33e751e33f0",
            "31a32a91f0054d23b75d94ce6524baa8",
            "8538280fa68542729f00389ca227266c",
            "6fe83f42266742a0b91e0ab9f7acce6c",
            "8fad7837f0054fc9b5ed0fbb3acd8793",
            "ad429c3a13834707852c4ab582e7bedb",
            "f6894fda37644288a923fd79e3a9afb0",
            "bf7937fc500a4d7d812b157fe8b597dc",
            "852179bc137a4c4fa83c37eb418d993b",
            "dac291da8fc84104a09e394b4eef28b7",
            "959ee251f360409b87f8d67bb59ba20a",
            "09c780657fd347ac88afe97a0ba9cb82",
            "71a03b0e4f794603a0b91ebd97d420eb",
            "2e2f54571a654da39e2a8004daf3124c",
            "f1bc9029521c45f6b8c8f0eb00fd7d4f",
            "f2fdf3cce0ff40e39aff780e81854822",
            "47b51fe5d64e46b896811f3d96704029",
            "749c1cf8fd464a1da528855d40fdc70d",
            "bf37d036c3d94d339f4f09c47a0c9795",
            "89d0a4fc1445465f8a430386dc1f4f08",
            "fc3860ae466c49a18d037cdea8178976",
            "68cf3b79a732432fa1faa9d28c66662f",
            "e3f094dab0f148919d30af40f23c66f7",
            "28ae4007a25a4c6e8484d1a3974fab48",
            "55218abcd81e4955be21a6634b01b1ff",
            "a211a26cdf4d44a4a1a76448a51f15a3",
            "4335c613f18d4372b286dcb0565695af",
            "5e4ec3db91fe4970a9483aa00cff1a7a",
            "a16030691b4e4d358bbda4aba0811ab5",
            "5de3c66469334089a06a917c94403233",
            "9dec7b7c78f849c7891bc2b5ed30940c",
            "51f573ffef244df08d99800e683aba62",
            "aa2e228e85c74a19b4f30d975ae6c7e1",
            "2405cc641a9b41e9a0e2a7200226230d",
            "e884b462959642179c48dcc8cdeae504",
            "c6fac57b36344359873529383d16c42e",
            "8554b34309114b53889872a969f8eaf6",
            "8e63b407151b4f178a9302b5b692b917",
            "31c69e0521d3401883882a8957efcef4",
            "2468a313d85645eaa9f08f21b1aa55ab",
            "4b9ba9f02dc54a399672e3bea97111b5",
            "3b863e3667244380910f45d5a6a33b6e",
            "b153337ee55b4a4691ad94932aed8f01",
            "2698049f8fbe4b0bad9e24378ac817ba",
            "c81bece39f8c4ae98b47ecaf431529ac",
            "33bf7d855877487383e5d9574daa572f",
            "2e59a7bbe65d42d7b6c938b58d8acc80",
            "3667c3e244824e9b81dde6c28e7b33fe",
            "7d1549485b7a4f51a885eba58bed5aaa",
            "a40e0892d6bf4f688b2c9459ce05ac56",
            "5934bd744ddf465098c48f87587a4e84",
            "e3ec53ee37a14677bf78df08b48df8ce",
            "17c89e4e70674ebc8210bf4ab0add059",
            "0080d62126844f19b800e6a08a8d58ef",
            "2cd6ee8a0c7a4716bdb405976c8d5e33",
            "d622152fc618498a903cb9d561cf8c68",
            "4137995ff6224239b08a7ae7930cb7a6",
            "ba7b356aad8c49b09ee5533433f3fedc",
            "6974964735ff4fc29dc9c6047e902105",
            "98e9172a95d94406bc8cd0cd5c23ac59",
            "6b7a74b545774891853e05d165ce9cf7",
            "60e86a08ad3c41eb87a3f70abdd2757e",
            "ee1d12d44d3041bdb2c2efb1c48c1182",
            "355a902372f1468b8d94c5f2ece0c53e",
            "7352013ac4bd47feb99297f37d030b30",
            "98f9c9af95c5414e99952240ef4a4290",
            "a9821bb8b2a84d5e83cbbf1f82e52526",
            "547a376b0ef14cc787fc7254e1f4117f",
            "eb3717f4aeae4daba81509849434af8f",
            "255900b25a52428ebae78952ed45913e",
            "e6ba39932555438f8ff362b18c67a82f",
            "b5015202578f4965afb875148854c19c",
            "ce275d58b21041539f574c442bdf770e",
            "a94e63ca1801461cb71d4980c705ddb2",
            "4c8ff1ce271b4e8db2a3dbfab0d94e02",
            "041bdd8faa8a456d94b1cf2f33ab296b",
            "b429b9370fa042d9b200a42b1a1300a2",
            "d13b4f3084fe4176a83b67a67b456c8d",
            "ef23fc347a934472ac15f1e0605a4df9",
            "e4982b49fa3148a189b278f1c7d933db",
            "2e5c2f5ba6f2463f9ce01eb96772c794",
            "54d5637dc8c946b2b53aaa672e9bbcc6",
            "fee7442350e94ef982a2c247da15333a",
            "8412b769bc52454fb37646da0986b43b",
            "6d93553cee1340dabe123552a924317c",
            "c008b4f452244f589a5c736c705e081e",
            "24e6c3cc5d484052a651482dcf99ff4b",
            "15b7015d81ae41bb8f8b9d14a7debb84",
            "66a654d1088e4652a64c27e53cd60708",
            "122ea06d1c1e4a25970a438a36aa9a8d",
            "3f8358aa869b4c759d4e1664b807214c",
            "7df9a3da1c884f1da46dd79ff34ab5f6",
            "90d9284de3184d7f85dc40eac64a6a02",
            "b8a847b27d84431f97491e71911135af",
            "2b2fc0f3b240471383aeb75e71bce5ff",
            "e2db148b066345e28ae897a817a44b4f",
            "e73eba4187dd4f68b97392f8a3561428",
            "621166a8ef314bceabf0f46bb2ae3aaf",
            "96492d7a6353498a8c52c090dfc40dd2",
            "b9ee923a0b1a4380ab3f88bb0aa70aef",
            "869b0871847c421d8eaa317ce2e2bb61",
            "48bb7d9238a144e5ae1d55c5a6f70ece",
            "d93123f23af34dc4aa5b82a8357f4eae",
            "bf695e743b9a4525bcc14ddd0edd1f7c",
            "5f1ab2b209a54ab5a0074450f5636e04",
            "e3fbe2799abd46798fa07f269b780f67",
            "9208af66ab7d4e409da1bd0a56bdbbb2",
            "9c3cf3db01324a1bb6c24b96e66fbae9",
            "f9eea919efa04bea9b35d3d353f96c00",
            "5dd5e42f4b44466ea60feef5f3420d93",
            "26bebae6eb8e4a68a4b89c8a5c2fb892",
            "5205e20e3571406a87ff684ff8486db7",
            "75e2ab8a72de4f73aa6a5057f66f707e",
            "7977d6a6af774f4589280ff14525830d",
            "5726f6a71196416f8d07dfcb118d50b4",
            "dc247ce3e50246f4b5eea2c1851f128f",
            "4018742044e449a3b39298565745056b",
            "649e6a421e744aa0857d1654c65d7f53",
            "77d4ed45384e491594a2389596d81800",
            "bb6a014185c34c32ab4de4fe497aea5d",
            "bd6e4ba423c04cbf869245aa3726dbd3",
            "796629a6c122400a94c609e7cd6ae848",
            "dc5a0027aac7423f9104051ade887df1",
            "ca527aaeea324926a4173ad4304dce15",
            "3af04179ad924547b7a3ee3b59733237",
            "8e6fdb8fdcea48baa7c40cf5ef75467b",
            "92f25132d2cb432ca56464751c3a16f9",
            "211d5383156141d6b745092fcd89c94b",
            "22e65d0e354c4c69a5b8bdc922edebac",
            "dbb77754689543fcb26830630d939f4e",
            "eb3fb7b213fc4e3eb18c91ad5bf350b0",
            "85ef19cadc9c49db81e19b01014784b5",
            "9341a31fc2f246cfa689d3bd32826f51",
            "d0eb9d02362d4f65bd21a51bc61c1b76",
            "b48ce13e0299496285489c7a30003d74",
            "98a561696256476ba8956ee718d6559d",
            "b9db18911785464fb567186d4af0e324",
            "f99ca24bf98045b3b130e2f37838b9b7",
            "8877e117f2824f14a52c0e861a76b885",
            "cc7d17eb70bd436d9d9ae2e8d3dfe21c",
            "a5fffaf70989412dbf645667a3d1ae88",
            "342bd321e2eb489daa060192f1f7be89",
            "b325f61bbdf645fda2cf98a84612e0ab",
            "b10e1bc9f6ac466fb5dce61a0d70ef27",
            "9dbe6bb9c3fa492a8d5b3022415d4cc8",
            "16ecdfb3c30e4d998ae8de2324d64060",
            "2bd69a92c4d34604a3e53448db63857c",
            "4dfe11f56c264351a7d07566a67006cf",
            "d72e89e2fe6947c98fd1ffb5c8beee1b",
            "6e9f321408f248dc86da00310e3eaf8f",
            "ee0444204e404fa6b664da1f7750c49b",
            "848aa9c61c7f408fb2bc5beb71fc6dd3",
            "012d042a834d4767a86f995240cadcc8"
          ]
        },
        "outputId": "5d94edb1-3f7d-4efa-96a6-72e48eaef687"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8fa5c315a964fa085e1a62f7848b7dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "959ee251f360409b87f8d67bb59ba20a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68cf3b79a732432fa1faa9d28c66662f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa2e228e85c74a19b4f30d975ae6c7e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2698049f8fbe4b0bad9e24378ac817ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cd6ee8a0c7a4716bdb405976c8d5e33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98f9c9af95c5414e99952240ef4a4290"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b429b9370fa042d9b200a42b1a1300a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15b7015d81ae41bb8f8b9d14a7debb84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96492d7a6353498a8c52c090dfc40dd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dd5e42f4b44466ea60feef5f3420d93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd6e4ba423c04cbf869245aa3726dbd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85ef19cadc9c49db81e19b01014784b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b325f61bbdf645fda2cf98a84612e0ab"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from sentence_transformers import SentenceTransformer,util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CTuc5ZMVjs2j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "corpus_embeddings = embedder.encode(sentences_list)\n",
        "\n",
        "# Normalize the embeddings to unit length\n",
        "corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "oubuEeZDzyTB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# source: https://stackoverflow.com/questions/55619176/how-to-cluster-similar-sentences-using-bert\n",
        "\n",
        "clustering_model = KMeans(n_clusters=4)\n",
        "clustering_model.fit(corpus_embeddings)\n",
        "cluster_assignment = clustering_model.labels_\n",
        "print(cluster_assignment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUMwFVkcz0td",
        "outputId": "d7e2f2a6-ceff-4736-eab1-37d916ba2b70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 1 3 1 1 3 2 1 1 1 1 3 3 1 1 1 1 1 3 0 1 3 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 3 3 3 3 3 3 3\n",
            " 3 1 1 1 2 2 2 1 2 1 2 2 2 3 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 1 2 2 1\n",
            " 1 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 3 3 1 3 3 1 1 3 2 3 1 3 2 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 1 1 3 2 2 3 2 3 3 3 3 3 1 2 2 3 3 3 3 3 3 3 3 2 2 1 2\n",
            " 1 2 2 3 3 3 3 3 3 3 1 1 2 1 1 0 0 3 1 3 2 2 3 3 3 3 3 0 2 1 0 0 2 0 2 3 3\n",
            " 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 0 0 0 0 0 3 0 2 0 2 1 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 2 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clustered_sentences = {}\n",
        "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "    if cluster_id not in clustered_sentences:\n",
        "        clustered_sentences[cluster_id] = []\n",
        "\n",
        "    clustered_sentences[cluster_id].append(sentences_list[sentence_id])\n",
        "# print(clustered_sentences)\n",
        "for k,v in clustered_sentences.items():\n",
        "    print(k,end=\"\\n\\n\\n\")\n",
        "    print(v,end=\"\\n\\n\\n\")\n",
        "# clustered_sentences[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRRlqrVpz1Wl",
        "outputId": "ffca2c5a-88ae-406b-cdfb-0499a5090691"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "\n",
            "\n",
            "['\\n\"computing\" refers to the process of using computers and computer systems to perform various\\ntasks, such as data processing, information storage, and solving complex problems .', 'in serial computing, each instruction or task must wait for the\\nprevious one to complete before it can be executed.', 'in a serial computing environment, a single processor would go through the entire dataset,\\ncomparing and rearranging numbers one pair at a time until the entire dataset is sorted.', 'these processors work in parall el, sorting their respective chunks simultaneously.', 'once all processors have completed sorting their portions, the sorted chunks can be combined to\\nproduce the final sorted dataset.', 'turn off or put to sleep any unused processors.', 'serial computing does not scale in this manner, as it relies on a single\\nprocessor.', 'it helps in designing and\\nanalyzing parallel processing systems\\n\\n1. single instruction single data (sisd ): in a sisd architecture, there is a single processor\\nthat executes a single instruction stream and operates on a single data stream.', 'this is the\\nsimplest type of computer architecture and is used in most traditional computers.', '2. single instruction multiple data (simd ): in a simd architecture, there is a single\\nprocessor that executes the same instruction on multiple data streams in parallel.', 'this type of\\narchitecture is used in applications such as image and signal processing.', '3. multiple instruction single data (misd ): in a misd architecture, multiple processors\\nexecute different instructions on the same data stream.', 'this type of architecture is not\\ncommonly used in practice, as it is difficult to find applications that can be decomposed into\\nindepen dent instruction streams.', '4. multiple instruction multiple data (mimd ): in a mimd architecture, multiple processors\\nexecute different instructions on different data streams.', 'this type of architecture is used in\\ndistributed computing, parallel processing, and other high -performance computing applications.', 'each processing unit loads its assigned subset of data.', 'for example, it may be between a parallel mpi\\nimplementation on all the cores of the node of a computer versus the gpu(s) on a node\\nhow parallel computing works\\nas a developer, you are responsible for the application software layer, which includes your source code.', 'in the source code, you make choices about the programming language and parallel software interfaces\\nyou use to leverage the underlying hardware.', 'a compiler is designed to translate your source code into a form the hardware can execute.', 'with these instructions at hand, an os manages executing these on the computer hardware.', 'here are some common parallel computing approach models:\\nhardware models\\ndistributed memory architecture: a cross -node parallel method :\\nparallel approach models\\nhardware models\\ndistributed memory architecture:\\na cross -node parallel method :\\nshared memory architecture: an\\non-node parallel method\\nvector units: multiple operations\\nwith one instruction\\naccelerator device: a special -\\npurpose add-on processor\\nsoftware models\\nprocess -based parallelization :\\nmessage passing\\nthread -based parallelization :\\nshared data via memory\\nvectorization : multiple\\noperations with one instruction\\nstream processing : through\\nspecialized processors\\ndistributed memory architecture, also known as distributed memory parallelism, is a parallel\\ncomputing method where multiple processors or nodes in a cluster have their own private memory.', 'in this architecture, each node opera tes independently and has its own local\\nmemory, and data sharing is achieved explicitly through message passing.', 'each node\\nworks on its subset of the data or a specific portion of the computation.', 'shared memory architecture: an on-node parallel method\\nin shared memory architecture, multiple processors or cores share a single, unified memory space.', 'this shared memory can be accessed and modified by any processor within the system.', 'on -node\\nparallelism, within the context of shared memory architecture, ref ers to parallel processing\\ntechniques that occur on a single computing node.', 'in this approach, multiple threads or processes\\nrun concurrently on the same node, accessing shared memory to perform computations .', 'vector units: multiple operations with one instruction\\nvector units, also known as vector processors, are specialized hardware units that can perform\\nmultiple operations with a single instruction.', 'these units are designed to process vectors, which are\\narrays of data elements, simultaneously.', 'vecto r processing is particularly useful in scenarios where\\nthe same operation needs to be performed on a large set of data elements .', 'vector processing example with four array elements operated on simultaneously\\naccelerator device: a special -purpose add-on processor\\ngpus come in two varieties: integrated and discrete.', 'discrete or dedicated gpus typically have a\\nlarge number of streaming multiprocessors and their own dram.', 'accessing data on a discrete gpu\\nrequires communication over a pci bus\\nan accelerator device, often referred to as an accelerator, is a specialized hardware component\\n(gpu) designed to perform specific types of computational tasks or workloads efficiently.', 'accelerators are typically used in conjunction with a central processin g unit (cpu) and are especially\\nwell-suited for workloads that can benefit from parallel processing and offloading certain tasks from\\nthe cpu.', 'accelerators are sometimes called \"add -on processors\" because they augment the\\nprocessing capabilities of a syste m.\\ngeneral heterogeneous parallel architecture model\\nnow let’s combine all of these different hardware architectures into one model .', 'two nodes, each\\nwith two cpus, share the same dram memory.', 'each cpu is a dual -core processor with an\\nintegrated gpu.', 'a discrete gpu on the pci bus also attaches to one of the cpus.', 'though the cpus\\nshare main memory, these are commonly in different non -uniform memory access (numa)\\nregions.', 'this means that accessing the second cpu’s memory is more expensive than getting at it’s\\nown memory\\nfig 5: a general heterogeneous parallel architecture model consisting of two nodes connected by\\na network.', 'each node has a multi -core cpu with an integrated and discrete gpu and some\\nmemory (dram).', 'it involves dividing a task into multiple processes or threads that run\\nindependently on separate computing nodes or cores.', 'this approach is widely used in distributed memory systems,\\nsuch as clusters and supercomputers.', 'the os places the processes on the cores\\nof two nodes.', 'the question marks i ndicate that the os controls the placement of the processes\\nand can move these during run time as indicated by the dashed arrows.', 'the os also allocates\\nmemory for each process from the node’s main memory\\n\\uf0b7 thread -based parallelization : shared data via memory\\nthread -based parallelization involves dividing a task into multiple threads that share the same\\nmemory space within a single process.', 'these threads can run concurrently on multiple cpu cores,\\nand they communicate and coordinate by accessing shared data in the shared memory.', 'this\\napproach is commonly used in multi -core processors and symmetric multiprocessing (smp) systems.', 'some memory is shared between threads.', '\\uf0b7 vectorization : multiple operations with one instruction\\nvectorization is a parallel computing technique that enables processors to perform multiple\\noperations with a single instruction.', 'it takes advantage of simd (single instruction, multiple data)\\ncapabilities found in modern processors, including cpus and gpus.', 'simd allows a single instruction\\nto operate on multiple da ta elements simultaneously, which can significantly accelerate\\ncomputations involving large datasets.', '\\uf0b7 stream processing : through specialized processors\\nstream processing, often referred to as stream computing or data stream processing, is a computing\\nparadigm where data is continuously processed as it is generated or ingested, rather than being\\nstored in traditional databases or file systems.', 'stream proce ssing is particularly useful for handling\\nlarge volumes of real -time data from various sources, such as sensors, social media, financial\\ntransactions, and iot devices.', 'specialized processors designed for stream processing accelerate the\\nanalysis and manipu lation of data streams, ensuring timely and efficient processing\\nin the stream processing approach, data and compute kernel are offloaded to the gpu and its\\nstreaming multiprocessors.', 'processed data, or output, transfers back to the cpu for file io or other\\nwork\\nsample application\\nwe start with a 2d problem domain of a region of space.', 'this can be an average\\n(a blur operation, which blurs the image )gradient (edge -detection, which sharpens the edges in the\\nimage) or another more complex operation associated with solving physical sys tems described by\\npartial differential equations (pdes)\\nstep 3: vectorization to work on more than one unit of data at a time\\nsome processors have the ability to operate on more than one piece of data at a time; a capability\\nreferred to as vector operations.', 'the shaded blocks in figure illustrate how multiple data values\\nare operated on simultaneously in a vector unit in a proce ssor with one instruction in one clock\\ncycle.', 'step 4: threads to deploy more than one compute pathway to engage more processing cores\\nbecause most cpus today have at least four processing cores, we use threading to operate the cores\\nsimultaneously acros s four rows at a time.', 'step 5: processes to spread out the calculation to separate memory spaces\\nwe can further split the work between processors on two desktops, often called nodes in parallel\\nprocessing.', 'when the work is split across nodes, the memory spaces for each node are distinct and\\nseparate.', 'step 6: off -loading the calculation to gpus\\non a gpu, the vector length is much larger than on a cpu.', 'here, 8×8 tiles are distributed across\\ngpu work groups.', 'application’s potential performance limits\\n\\uf0b7 flops (floating -point operations)\\n\\uf0b7 ops (operations) that include all types of computer instructions\\n\\uf0b7 memory bandwidth: rate at which the data is transferred\\n\\uf0b7 memory latency: time required for the first byte or word of data to be transferred\\n\\uf0b7 instruction queue (instruction cache)\\n\\uf0b7 networks\\n\\uf0b7 disk\\n\\uf0b7 machine balance: number of flops executed /memory bandwidth\\n\\uf0b7 arithmetic intensity : number of flops executed per memory operation\\nall of these limitations can be divided into two major categories:.', 'it includes all types of computer operations.', 'feeds include the memory bandwidth through the\\ncache hierarchy, as well as network and disk bandwidth .', 'for many applications, the memory bandwidth limit can be difficult especially dealing with non-\\ncontiguous bandwidth.it is also known as strided memory access or non -contiguous memory\\naccess, refers to the manner in which data elements are accessed in memory.', 'in contrast to\\ncontiguous memory access, where elements are stored in consecutive memory locations, non -\\ncontiguous memory access invo lves accessing elements that are not stored sequentially in memory.', 'non -contiguous memory access:\\nnow, consider a situation where the array elements are scattered in memory with a stride of 2. this\\nis a non -contiguous memory access pattern:\\nin this case, accessing every second element (stride = 2) would mean accessing memory locations 1,\\n2, 3, 4, 5, etc., but the elements are not stored sequentially.', 'when your program needs to access such non -contiguous elements, it may lead to inefficiencie s\\ndue to increased cache misses and a higher likelihood of accessing data from main memory rather\\nthan the faster cache memory.', 'text view\\nthe information from the lscpu command and the /proc/cpuinfo file helps to determine the number\\nof processors, the processor model, the cache sizes, and the clock frequency for the system\\ncalculating theoretical maximum flops\\ntheoretical flops=number of cores×clock speed×flops per cycle per core\\nwhere:\\n\\uf0b7 number of cores: this represents the total number of processor cores in the computing\\nsystem.', '\\uf0b7 clock speed: this indicates the clock speed of each core in the system, typically measured\\nin hertz (hz) or gigahertz (ghz).', 'it represents the number of cycles th e processor can\\nexecute per second.', '\\uf0b7 flops per cycle per core: this signifies the number of floating -point operations a core can\\nperform in a single clock cycle.', 'modern processors often perform multiple flops per cycle\\ndue to features like simd (single inst ruction, multiple data) operations.', \"for example, let's consider a system with 4 cores, each operating at 3.0 ghz, and capable of\\nexecuting 4 flops per cycle per core (assuming simd operations are utilized):\\ntheoretical flops=4\\u2009cores×3.0\\u2009ghz×4\\u2009flops per cycle per core\\ntheoretical flops=48\\u2009gflops\\nthe memory hierarchy and theoretical memory bandwidth\\nwe can calculate the theoretical memory bandwidth of the main memory using the memory chips\\nspecifications.\", 'the general formula is b t = mtr × mc × tw × ns = data transfer rate × memory channels × bytes\\nper access × sockets\\nprocessors are installed in a socket on the motherboard.', 'the motherboard is the main system board\\nof the computer, and the socket is the lo cation where the processor is inserted.', 'most motherboards\\nare single -socket, where only one processor can be installed.', 'dual -socket motherboards are more\\ncommon in high -performance computing systems.', 'two processors can be installed in a dual -socket\\nmotherb oard, giving us more processing cores and more memory bandwidth.', 'if a single byte of m emory is requested, it takes 1 cycle to retrieve\\nit from a cpu register.', 'if it is not in the cpu register, it comes from the l1 cache.', 'if it is not in the l1\\ncache, the l1 cache loads it from l2 and so on to main memory.', 'if it goes all the way to main\\nmemo ry, for a single byte of memory, it can take around 400 clock cycles.', 'this time required for the\\nfirst byte of data from each level of memory is called the memory latency .', 'calculatin g the machine balance between flops and bandwidth\\nthe machine balance is the flops divided by the memory bandwidth.']\n",
            "\n",
            "\n",
            "1\n",
            "\n",
            "\n",
            "['this computing can be either done in serial way known as serial computing or in parallel wa y\\nknown as parallel computing\\nserial computing:\\nserial computing refers to traditional computing where tasks are executed sequentially, one after\\nthe other, using a single processor.', 'this approach limits the speed and efficiency\\nof processing, especially when dealing with complex or time -consuming tasks.', 'computing\\nserial or\\nsequential parallel example of serial computing : consider a task of sorting a large dataset of numbers in ascending\\norder.', 'parallel computing\\nparallel computing is a type of computation in which multiple processors or computers work together\\nto solve a problem.', 'instead of one single processor handling the entire task, parallel computing divides\\nthe task into smaller sub -tasks that can be processed simultaneously.', 'this simultaneous processing\\ncan lead to significant improvements in computational speed and efficien cy.', 'example of parallel computing: using the same example of sorting a large dataset, parallel computing\\nwould involve dividing the dataset into smaller chunks, and each chunk is sorted independently by a\\nseparate processor.', 'definition parallel computing is the practice of identifying and exposing parallelism in algorithms,\\nexpressing this in our software, and understanding the costs, benefits, and limitations of the chosen\\nimplementation.', 'benefits of parallel computing\\n\\n\\uf0b7 faster run time with more compute cores: parallelization involves dividing a task into\\nsmaller sub -tasks that can be executed simultaneously, utilizing multiple cores to process the\\ndata.', 'this approach can significantly reduce the time required to complete the task, as each\\ncore works on a separate portion of the problem concurrently.', '\\uf0b7 larger problem sizes with more compute nodes : with more nodes, you can break down your\\nproblem into smaller pieces that each node can work on simultaneously, which is especially\\nbeneficial for handling larger datasets and more complex simulations .', '\\uf0b7 energy efficiency by doing more with less: in the context of parallel computing, the concept\\nof \"doing more with less\" often revolves around optimizing energy efficiency while achieving\\nbetter computational performance.this can be achieved by making use of dynamic resource\\nallocation and workload consolidation to ensure that the number of processors used is\\nproportional to the workload.', '\\uf0b7 scalability : parallel computing can be easily scaled by adding more processors, which further\\nenhances performance.', '\\uf0b7 parallel computing can reduce costs: as technology advances, the cost of individual\\nprocessors and memory decreases.', 'parallel computing systems can take advantage of these\\ncost reductions, making it more economical to build high -performance computing clusters or\\ndata centers .', 'applications of parallel computing:\\n\\uf0b7 scientific simulations: used in fields such as physics, chemistry, and engineering for\\ncomplex simulations.', '\\uf0b7 big data processing: parallel computing is crucial in processing vast amounts of data in\\nfields like data analytics and machine learning.', '\\uf0b7 video and image processing: parallelism accelerates tasks like video rendering and\\nimage recognition.', \"fundamental laws\\nfundamental laws in parallel computing, such as amdahl's law and gustafson's law, are essential\\nfor understanding the limitations and possibilities of parallel processing.\", 'these laws provide valuable\\ninsights into how the speedup of a parallel algorithm is affected by various factors .', 'what is speedup?', 'speedup in parallel computing refers to the performance improvement achieved by using multiple\\nprocessors or computing resources to solve a problem compared to using a single processor.', 'it is a\\nmeasure of how much faster a parallel algorithm or system can complet e a task compared to a serial\\n(single -processor) implementation of the same task.', 'speedup is a crucial metric for evaluating the\\neffectiveness of parallel computing systems.', 'the speedup ( s) can be calculated using the following formula:\\ns=tserial / tparallel\\nwhere:\\n\\uf0b7 tserial is the execution time of the task using a single processor (serial execution time).', 'tparallel is the execution time of the task using multiple processors (parallel execution time).', 'a speedup value greater than 1 indicates that the parallel implementation is faster than the serial\\nimplementation.', 'ideally, in a perfectly parallelizable task, doubling the number of processors would ideally halve the execution time, resulting in a speedup of 2. however, achieving perfect linear\\nspee dup is rare in real -world scenarios due to factors such as communication overhead, load\\nbalancing issues, and synchronization constraints between processors.', \"amdahl's law is a fundamental principle in parallel computing that expresses the potential\\nspeedup of a parallel algorithm as a function of the proportion of the algorithm that can be\\nparallelized.\", 'it was formulated by gene amdahl in 1967 and is represented by the fol lowing\\nformula:\\nwhere:\\n\\uf0b7 speedup is the improvement in performance achieved by parallelizing a computation\\ncompared to executing it sequentially.', '\\uf0b7 p is the proportion of the algorithm that can be parallelized (a value between 0 and 1).', \"\\uf0b7 s is the serial fraction\\n\\uf0b7 n – no.of processors/nodes/cores\\namdahl's law highlights the limitations of parallel computing.\", 'it states that the speedup of a\\nprogram using multiple processors in parallel computing is limited by the sequential fraction of\\nthe program.', 'in other words, if only a portion of a program can be parallelized (the rest being\\ninherently sequential), then no matter how many processors are added, there will always be a\\nlimit to the speedup that can be achieved.', \"for example, if 90% of a program can be parall elized (p = 0.9) and the parallel portion runs on\\n5 processors , the maximum speedup that can be achieved according to amdahl's law is:\\nspeedup= 1/(0.1+(0.9/5))=3.57\\nin this case, even though 90% of the program can be parallelized and runs on 5 processors , the\\nmaximum speedup achievable is approximately 3.57 times faster compared to the sequential\\nexecution due to the presence of the 10% sequential portion.\", 'fig : speedup for a fixed -size problem according to amdahl’s law is shown as a function of the\\nnumber of processors.', 'lines show ideal speedup when 100% of an algorithm is parallelized,\\nand for 90%, 75%, and 50%.', 'amdahl’s law states that speedup is limited by the fractions of\\ncode that remain serial.', \"gustafson's law , formulated by john l. gustafson, provides a different perspective on parallel\\ncomputing compared to amdahl's law.\", \"the basic idea behind g ustafson's law is\\nthat as the size of the problem increases, the impact of the parallelizable portion of the program\\nbecomes more significant, leading to better scalability.\", 'in other words, with larger problem sizes,\\nparallel systems can achieve higher lev els of speedup.', \"the formula for gustafson's law is as follows:\\nspeedup(n) = n – s * (n – 1) where n is the number of processors, and s is the serial fraction\\nstrong scaling and weak scaling are two different m etrics used to evaluate the performance of\\nparallel computing systems, and they provide insights into how well a parallel algorithm or\\napplication can handle an increasing workload or an increasing number of processors.\", \"here's a\\ncomparison of strong scalin g and weak scaling:\\nstrong scaling:\\ndefinition: strong scaling measures how the execution time of a fixed problem size decreases\\nas the number of processors increases.\", 'in other words, it assesses how well a parallel system\\nperforms when the size of the problem remains constant, but the number of proces sors used\\nto solve the problem increases.', 'objective: the goal of strong scaling is to reduce the execution time for a fixed problem size by\\nutilizing more processors.', 'it aims to speed up the solution of a specific problem.', 'scenario: strong scaling is applicable when the size of the problem is fixed, and the aim is to\\nsolve that problem faster by employing additional processors.', '2. weak scaling:\\ndefinition: weak scaling measures how the execution time changes as both the problem size\\nand the number of processors increase proportionally.', 'in other words, it assesses how well a\\nparallel system can handle larger workloads by adding more processors as the problem size\\ngrows.', 'objective: the goal of weak scaling is to maintain a constant workload per processor as the size\\nof the problem and the number of processors increase.', 'it aims to solve larger problems in\\napproximately the same amount of time per processor.', 'scenario: weak scaling is applicable when the problem size can be increased, and the aim is to\\nhandle larger workloads by distributing the computational load across a larger number of\\nprocessors.', \"parallel approaches (flynn’s classification)\\n\\nflynn's classification is essential in the field of parallel computing because it provides a framework\\nfor understanding and categorizing different types of computer architectures based on the number\\nof instruction streams and data streams.\", 'the taxonomy highlights the importance of parallelism in modern computing and shows how\\ndifferent types of parallelism can be exploited to improve performance.', 'parallel strategies\\nparallel strategies\" typically refer to techniques and methods for parallel processing, which is the\\nsimultaneous execution of multiple tasks or processes to improve the efficiency and performance\\nof a computer system.', 'parallel strategies are commonly used in various computing domains, such\\nas high -performance computing and distributed systems, to speed up computations and handle\\nlarge volumes of data.', 'here are some common parallel s trategies:\\ndata parallel approach\\ndata parallelism involves performing the same operation on multiple data elements simultaneously.', 'the sentiment analysis process is computationally intensive, and you want to\\nspeed it up using data parallelism.', 'to apply data\\nparallelism, you divide this dataset into smaller, non-overlapping subsets.', 'task parallelism(main -worker approach)\\ntask parallelism involves executing multiple independent tasks or processes in parallel.', 'task\\nparallelism is common in applications where different tasks can be performed concurrently without\\ndependencies between them.', 'in a task parallelism setup, these tasks can be executed concurrently by multiple threads or\\nprocesses, allowing the server to handle multiple incoming requests simultaneously without waiting\\nfor one task to complete before starting the next.', 'in parallel computing, the concept of bucket -brigade parallelism involves breaking down a task into\\nsmaller subtasks, where each subtask is processed independently and passed to the next processing\\nunit for further computation.', 'this technique allows for efficient parallel processing of tasks and is\\noften used in scenarios where tasks can be divided into smaller, manageable parts.', 'parallel speedup versus comparative speedups.', 'parallel speedup and comparative speedup are two different metrics used to evaluate the performance\\nimprovement achieved by parallel processing.', 'parallel speedup measures how much faster a parallel algorithm runs compared to its sequential\\n(single -processor) counterpart.', 'it quantifies the performance improvement gained by using multiple\\nprocessing units in parallel.', 'parallel speedup is calculated using the followi ng formula:\\nparallel speedup=sequential execution time/parallel execution\\nin this formula:\\n\\uf0b7 sequential execution time is the time taken by the algorithm to execute sequentially on a\\nsingle processor.', '\\uf0b7 parallel execution time is the time taken by the paralle l algorithm to execute on multiple\\nprocessors.', 'comparative speedup : comparative speedup is between architectures.', 'this is usually a\\nperformance comparison between two parallel implementations or other comparison between\\nreasonably constrained sets of hardware.', 'additionally, you decide how to break up your work into\\nparallel units.', 'parallel approach models are used to express parallelization in an application software layer\\nthat gets mapped to the computer hardware through the compiler and the os.', 'parallel computing\\napproaches involve various models and paradigms that define how tasks are divided, coordinated, and\\nexecuted in parallel systems.', 'in the context of distributed memory architecture, a \"cross -node parallel method\" refers to parallel\\nprocessing techniques that involve distributing tasks across multiple nodes in a cluster.', 'software models\\nthe programmer must first expose the parallelization, determine the best technique to operate in\\nparallel, and then explicitly direct its operation in a safe, correct, and efficient manner.', 'the following\\nmethods are the most common techniques for parallelization\\n\\uf0b7 process -based parallelization : message passing\\nprocess -based parallelization, particularly through message passing, is a common approach in\\nparallel computing.', 'fig 7: the application process in a thread -based approach to parallelization spawns\\nthreads.', 'for all of these options, calculation speed is critical if we want real -time result s\\nto inform our decisions.', 'define a computational kernel (operation) to conduct on each element of the mesh\\n3. add the following layers of parallelization on cpus and gpus to perfo rm the calculation:\\nvectorization —work on more than one unit of data at a time\\n4. threads —deploy more than one compute pathway to engage more processing cores\\n5. processes —separate program instances to spread out the calculation into separate memory\\nspaces\\n6. off -loading the calculation to gpus —send the data to the graphics processor to calculate\\nstep 1: discretize the problem into smaller cells or elements\\nthe domain is discretized into cells.', 'performance limits and profiling\\nin parallel processing, understanding performance limits and profiling the application are crucial\\nsteps to optimize the execution of parallel programs.', 'performance limits refer to the maximum achievable performance of a computing system or\\napplication un der specific conditions.', 'understanding\\nthese performance limits is essential for designing efficient algor ithms, optimizing software, and\\nchoosing appropriate hardware configurations.', 'it also guides researchers and engineers in\\ndeveloping new technologies to overcome existing limitations and improve overall computing\\nperformance.', 'speeds are how fast operations can\\nbe done.', 'for instance, in\\nparallel computing, theoretical analysis can reveal the maximum speedup or efficiency that a\\nparallel algorithm can achieve in an ideal scenario .', \"analyzing call graphs in parallel programming can provide valuable insights in to the program's\\nstructure, dependencies, and potential performance optimizations .\", 'optimizing these hot -spots is e ssential for improving overall parallel program\\nperformance.', 'parallel algorithms and patterns\\na parallel algorithm is a step -by-step computational procedure or set of rules designed to be\\nexecuted on parallel computing architectures.', 'these algorithms are specifically crafted to take\\nadvantage of parallel processing capabilities, where multiple proces sors or cores can work together\\nto solve a problem.', 'parallel patterns are like reusable blueprints that help programmers apply proven methods to solve\\nspecific types of problems efficiently.', 'these patterns guide the decomposition of tasks and data,\\nprovidi ng a framework for creating effective parallel algorithms .', 'example : parallel algorithm for finding the maximum element:\\nsuppose you have a large array of numbers, and you want to find the maximum element using a\\nparallel algorithm based on the \"divide an d conquer\" pattern.in this example, the \"divide and\\nconquer\" pattern is applied to find the maximum element in an array.', 'the array is divided into\\nsmaller subarrays, and the maximum values of these subarrays are found in parallel.', 'algorithm analysis for parallel computing applications\\nthe goal of algorithm analysis is to compare different algorithms that are used to solve the same\\nproblem.', 'one of the more traditional ways to evaluate algorithms is by looking at their algorithmic\\ncomplexity.']\n",
            "\n",
            "\n",
            "2\n",
            "\n",
            "\n",
            "['this process\\noccurs sequentially, and each comparison and rearrangement must wait for the previous one to\\nfinish.', '\\uf0b7 weather forecasting: enables complex weather simulations and predictions.', '\\uf0b7 financial modelling : used for risk analysis, option pricing, and other complex financial\\ncalculations.', \"unlike amdahl's law, which focuses on fixed problem sizes,\\ngustafson's law takes into account varying problem sizes.\", 'this classifica tion is named after michael j. flynn, who\\nintroduced it in 1966. flynn’s taxonomy is a useful tool for understanding different types of\\ncomputer architectures and their strengths and weaknesses.', 'this strategy is often used in applications where the same operation can be applied to different\\npieces of data independent ly.', \"scenario : imagine you're running a data analysis task on a large dataset of customer reviews for a\\nproduct.\", \"your goal is to perform sentiment analysis on each review to determine if it's positive,\\nnegative, or neutral.\", 'data parallelism in sentiment analysis :\\n1. data preparation : you have a dataset of 1,000,000 customer reviews.', \"let's say you split\\nit into four subsets, each containing 250,000 reviews.\", '2. parallel processing : you have a sentiment analysis model that can analyze reviews.', 'you set\\nup four separate processing units (e.g., cpu cores or machines in a cluster), each responsible\\nfor analyzing one subset of reviews.', '3. analysis : each processing unit applies the sentiment analysis model to its subset of reviews\\nindependently and simultaneously.', 'for in stance:\\n\\uf0b7 processing unit 1 analyzes reviews 1 to 250,000.', '\\uf0b7 processing unit 2 analyzes reviews 250,001 to 500,000.', '\\uf0b7 processing unit 3 analyzes reviews 500,001 to 750,000.', '\\uf0b7 processing unit 4 analyzes reviews 750,001 to 1,000,000.', '4. aggregation : as each processing unit finishes its analysis, it generates results, such as counts\\nof positive, negative, and neutral reviews within its subset.', 'these results are temporarily\\nstored.', '5. combining results : after all processing units have completed their work, you combine the\\nresults.', 'you sum up the counts from each processing unit to get the overall sentiment\\nanalysis results for the entire dataset.', 'each task\\ncan perform different operations and may not necessarily operate on the same data.', 'in the main -worker approach, one processor schedules and distributes the tasks for all the workers,\\nand each worker checks for the next work item as it returns the previous completed task .', 'example: web server handling requests\\nconsider a web server handling incoming http requests.', 'each i ncoming request is an independent\\ntask that can be processed concurrently.', 'the tasks include tasks like parsing the request, querying\\nthe database, and generating the response.', 'in a task parallelism scenario:\\n1. task 1: parsing request\\n\\uf0b7 this task involves pars ing the incoming http request to extract information like the\\nrequested url, parameters, and headers.', '2. task 2: database query\\n\\uf0b7 this task involves querying a database to fetch data related to the request, such as\\nuser information or product details.', '3. task 3: generating response\\n\\uf0b7 this task involves generating an html response based on the parsed request and\\ndata retrieved from the database.', 'bucket -brigade parallelism :\\na bucket brigade is a method of manually transporting items or materials from one location to\\nanother by forming a line of people, each of whom carries an item and passes it to the next person.', 'this technique is similar to how buckets of water might be passed along a line of people to put out a\\nfire, which is where the term \"bucket brigade\" originated.', \"example: manufacturing assembly line\\nlet's say we have a manufacturing assembly line for producing smartphones.\", 'the assembly line\\nconsists of three stages: a, b, and c. each stage represents a specific task in the smartphone\\nassembly process.', '1. stage a - component assembly :\\n\\uf0b7 worker a assembles the basic components of the smartphone, such as the circuit\\nboard, battery, and display.', 'once worker a finishes assembling a smartphone, it passes it\\nto stage b.', '2. stage b - software installation :\\n\\uf0b7 worker b installs the operating system and necessary software onto the smartphone\\nassembled by worker a. after software installation, the smartphone is passed to stage c.\\n3. stage c - quality control and packaging :\\n\\uf0b7 worker c checks the smartphone for quality control, ensuring that all components\\nare working correctly an d the software is functioning as intended.', 'if the smartphone passes\\nquality control, it is packaged and prepared for shipment.', 'in this example, each stage (a, b, and c) represents a processing step, similar to the stages in a\\nbucket -brigade parallelism sce nario.', 'these nodes are connected via a network, and they communicate and coordinate with each other\\nby passing messages.', 'communication and\\ncoordination between nodes are essential, as tasks often depend on results or data computed on\\nothe r nodes.', 'these processes communicate and\\ncoordinate with each other by sending and receiving messages.', 'message passing is a method of\\ninter -process communication where data and instructions are exchanged between processes to\\nsynch ronize and share information.', 'fig 6 : the message passing library spawns processes.', 'the threads are restricted to the node’s domain.', 'the question marks show that\\nthe os decides where to place the threads.', 'for purposes of illustration, we will use\\na 2d image of the krakatau volcano as our example.', 'the goal of our calculation could be to model\\nthe volcanic plume, the resulting tsunami, or the early detection of a volcanic eruption using\\nmachine learning.', '1. discretize (break up) the problem into smaller cells or elements\\n2 .', 'for each cell in the computational domain, properties such as\\nwave height, fluid velocity, or smoke density are solved for according to physical laws.', 'ultimately, a\\nstencil operation or a matrix -vector system represents this discrete scheme\\nstep 2: define a computational kernel, or operation, to conduct on each element of the mesh\\nthe calculations on this discretized data are often some form of a stencil operation, so -called because\\nit involves a pattern of a djacent cells to calculate the new value for each cell.', 'these limits are determined by various factors and constraints\\nand play a crucial role in understanding the capabilities and limitations of a system.', 'but to be able to do the operations, you must\\nget the data there.', 'this is where feeds come in.', 'theoretical measurements provide an upper limit to what a system can achieve.', 'lstopo is bundled with the hwloc package that com es with nearly every mpi\\ndistribution.', 'figure below\\nshows the output for a mac laptop in graphical view.', 'additionally, you should\\ndevelop an understandi ng of how different subroutines and functions depend on each other .', \"they illustrate how\\nfunctions or tasks invoke each other and provide a visual representation of the program's control\\nflow.\", 'finally, the\\nmaximum amon g these partial maximums is selected as the maximum element of the entire array.']\n",
            "\n",
            "\n",
            "0\n",
            "\n",
            "\n",
            "['the energy consumption for your applicat ion can be estimated using the formula\\np = (n processors) × (r watts/processors) × (t hours)\\nwhere p is the energy consumption, n is the number of processors, r is the thermal design\\npower, and t is the application run time.', 'profiling tools are used to ga ther detailed information about the behavior of a parallel program.', 'by\\nunderstanding performance limits, utilizing profiling tools, and optimizing the code based on the\\nprofiling results, developers can enhance the efficiency of parallel applications, lea ding to improved\\nspeedup and overall performance.', 'determine your hardware capabilities:\\nto determine the performance of hardware the following metrics are used :\\n\\uf0b7 the rate at which floating -point operations can be executed (flops/s)\\n\\uf0b7 the rate at which data can be moved between various levels of memory (gb/s)\\n\\uf0b7 the rate at which energy is used by your application (watts)\\nin determining hardware performance and calculating the metrics , we use a mixture of theoretical\\nand empirical measurements .', 'real -world validation is done by empirical measurements , they provide concrete evidence of how\\na system performs under real -world conditions, accounting for various factors like i/o operations,\\nnetwork latency, and concurrency issues.', 'one of the best tools for understanding the hardware you run is the lstopo program (graphical view)\\nand lscpu for text view .', 'this command outputs a graphical view of the hardware on your system.', 'empirical measurement of bandwidth and flop\\nthe empirical bandwidth is the measurement of the fastest rate that memory can be loaded from\\nmain memory into the processor.', 'two different methods are used for measuring the bandwidth: the stream benchmark and the\\nroofline model measured by the empirical roofline toolkit.', 'key differences:\\n\\uf0b7 focus: stream primarily focuses on memory bandwidth, providing quantitative\\nmeasurements.', 'in contrast, the roofline model provides a graphical representation of\\nperformance bottlenecks, considering both computational capabilities and memory\\nbandwidth.', '\\uf0b7 representation: stream results in a numerical measurement (memory bandwidth in bytes\\nper second), while the roofline model is a graphical representation that helps v isualize\\nperformance limitations.', \"\\uf0b7 insights: stream provides detailed insights into memory subsystem performance, whereas\\nthe roofline model offers a high -level overview of an application's performance efficiency\\nconcerning hardware constraints.\", 'we can calculate both a theoretical machine balance (mb t) and an empirical machine balance (mb e)\\nlike so:\\nmb t = f t / b t\\nmb e = f e / b e\\ncharacterizing your application: profiling\\nnow that you have some sense of what performance you can get with the hardware, you need to\\ndetermine what are the performance characteristics of your application.', 'profiling tools :\\nusing call graphs for hot -spot and dependency analysis\\nin the context of parallel programming, call graphs are diagrams that represent the calling\\nrelationships between different functions or methods in a parallel program.', 'by analyzing these call graphs,\\ndevelopers can identify hot -spots —functions or tasks that consume a significant amount of\\ncomputational time.', 'empirical measurement of processor clock frequency and energy consumption\\nempirical measurement of processor clock frequency:\\n1. profiling tools: profiling tools like intel vtune profiler or amd codexl can provide insights\\ninto various performance metrics, including processor clock frequency.', 'these tools often offer\\nvisualizations and detailed reports for better analysis.', '2. benchmarking suites: benchmarking tools like spec cpu benchmarks or hpc chal lenge\\nbenchmarks often include components that measure processor clock frequencies.', \"running\\nthese benchmarks can provide detailed information about the processor's performance\\ncharacteristics.\", '2. empirical measurement of energy consumption:\\n1. power measureme nt tools: use power measurement tools and hardware devices to\\nmeasure the power consumption of your system.', 'power meters and sensors can be attached\\nto the system to measure real -time power usage.', \"tools like intel power gadget or linux's\\npowerstat can help measure power usage.\", '2. energy profilers: some profiling tools, like intel vtune profiler, also offer energy profiling\\ncapabilities.', 'they can provide insights into energy consumption patterns at different parts of\\nyour code.', 'these tools often correlate energ y consumption with specific functions or code\\nregions.', 'tracking memory during run time\\ntracking memory usage during runtime in parallel computing is crucial for optimizing performance,\\ndetecting memory leaks, and ensuring efficient memory management.', 'several techniques and tools\\ncan help you monitor memory usage in parallel applications.', 'here are some approaches to tracking\\nmemory during runtime in parallel computing environments:\\nprofiling tools:\\n1. valgrind massif: valgrind is a powerful instrumentation framework.', 'massif, a valgrind tool, can\\nprofile heap memory usage over time, showing memory consumption patterns.', \"it's particularly\\nuseful for detecting memory leaks and understanding how memory usage evolves during\\nprogram execution.\", '2. intel vtune profiler : vtune profiler provides memory analysis capabilities, including memory\\nusage tracking.', 'it can analyze memory consumption at various levels, from individual functions\\nto entire applications, in both serial and parallel contexts.', '3. openmp/mpi memory profiler s: many parallel programming frameworks like openmp and\\nmpi provide their memory profiling tools.', 'for example, openmp has tools like score -p, and mpi\\nhas memory profiling features integrated into mpi implementations.']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=\" \".join(clustered_sentences[0])\n",
        "print(s)\n"
      ],
      "metadata": {
        "id": "DucNc8jD1gpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41698ee0-7209-4045-e549-5bc4ffb999e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the energy consumption for your applicat ion can be estimated using the formula\n",
            "p = (n processors) × (r watts/processors) × (t hours)\n",
            "where p is the energy consumption, n is the number of processors, r is the thermal design\n",
            "power, and t is the application run time. profiling tools are used to ga ther detailed information about the behavior of a parallel program. by\n",
            "understanding performance limits, utilizing profiling tools, and optimizing the code based on the\n",
            "profiling results, developers can enhance the efficiency of parallel applications, lea ding to improved\n",
            "speedup and overall performance. determine your hardware capabilities:\n",
            "to determine the performance of hardware the following metrics are used :\n",
            " the rate at which floating -point operations can be executed (flops/s)\n",
            " the rate at which data can be moved between various levels of memory (gb/s)\n",
            " the rate at which energy is used by your application (watts)\n",
            "in determining hardware performance and calculating the metrics , we use a mixture of theoretical\n",
            "and empirical measurements . real -world validation is done by empirical measurements , they provide concrete evidence of how\n",
            "a system performs under real -world conditions, accounting for various factors like i/o operations,\n",
            "network latency, and concurrency issues. one of the best tools for understanding the hardware you run is the lstopo program (graphical view)\n",
            "and lscpu for text view . this command outputs a graphical view of the hardware on your system. empirical measurement of bandwidth and flop\n",
            "the empirical bandwidth is the measurement of the fastest rate that memory can be loaded from\n",
            "main memory into the processor. two different methods are used for measuring the bandwidth: the stream benchmark and the\n",
            "roofline model measured by the empirical roofline toolkit. key differences:\n",
            " focus: stream primarily focuses on memory bandwidth, providing quantitative\n",
            "measurements. in contrast, the roofline model provides a graphical representation of\n",
            "performance bottlenecks, considering both computational capabilities and memory\n",
            "bandwidth.  representation: stream results in a numerical measurement (memory bandwidth in bytes\n",
            "per second), while the roofline model is a graphical representation that helps v isualize\n",
            "performance limitations.  insights: stream provides detailed insights into memory subsystem performance, whereas\n",
            "the roofline model offers a high -level overview of an application's performance efficiency\n",
            "concerning hardware constraints. we can calculate both a theoretical machine balance (mb t) and an empirical machine balance (mb e)\n",
            "like so:\n",
            "mb t = f t / b t\n",
            "mb e = f e / b e\n",
            "characterizing your application: profiling\n",
            "now that you have some sense of what performance you can get with the hardware, you need to\n",
            "determine what are the performance characteristics of your application. profiling tools :\n",
            "using call graphs for hot -spot and dependency analysis\n",
            "in the context of parallel programming, call graphs are diagrams that represent the calling\n",
            "relationships between different functions or methods in a parallel program. by analyzing these call graphs,\n",
            "developers can identify hot -spots —functions or tasks that consume a significant amount of\n",
            "computational time. empirical measurement of processor clock frequency and energy consumption\n",
            "empirical measurement of processor clock frequency:\n",
            "1. profiling tools: profiling tools like intel vtune profiler or amd codexl can provide insights\n",
            "into various performance metrics, including processor clock frequency. these tools often offer\n",
            "visualizations and detailed reports for better analysis. 2. benchmarking suites: benchmarking tools like spec cpu benchmarks or hpc chal lenge\n",
            "benchmarks often include components that measure processor clock frequencies. running\n",
            "these benchmarks can provide detailed information about the processor's performance\n",
            "characteristics. 2. empirical measurement of energy consumption:\n",
            "1. power measureme nt tools: use power measurement tools and hardware devices to\n",
            "measure the power consumption of your system. power meters and sensors can be attached\n",
            "to the system to measure real -time power usage. tools like intel power gadget or linux's\n",
            "powerstat can help measure power usage. 2. energy profilers: some profiling tools, like intel vtune profiler, also offer energy profiling\n",
            "capabilities. they can provide insights into energy consumption patterns at different parts of\n",
            "your code. these tools often correlate energ y consumption with specific functions or code\n",
            "regions. tracking memory during run time\n",
            "tracking memory usage during runtime in parallel computing is crucial for optimizing performance,\n",
            "detecting memory leaks, and ensuring efficient memory management. several techniques and tools\n",
            "can help you monitor memory usage in parallel applications. here are some approaches to tracking\n",
            "memory during runtime in parallel computing environments:\n",
            "profiling tools:\n",
            "1. valgrind massif: valgrind is a powerful instrumentation framework. massif, a valgrind tool, can\n",
            "profile heap memory usage over time, showing memory consumption patterns. it's particularly\n",
            "useful for detecting memory leaks and understanding how memory usage evolves during\n",
            "program execution. 2. intel vtune profiler : vtune profiler provides memory analysis capabilities, including memory\n",
            "usage tracking. it can analyze memory consumption at various levels, from individual functions\n",
            "to entire applications, in both serial and parallel contexts. 3. openmp/mpi memory profiler s: many parallel programming frameworks like openmp and\n",
            "mpi provide their memory profiling tools. for example, openmp has tools like score -p, and mpi\n",
            "has memory profiling features integrated into mpi implementations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6k4zTt3IlFLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dYoPlUrl2NFB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "   chunk_size=3096, chunk_overlap=0\n",
        ")\n",
        "chunks = text_splitter.split_text(s)\n",
        "# docs = text_splitter.create_documents([text])\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "HBlLaAmX2UMb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate,  LLMChain\n",
        "def generate_summary(text_chunk):\n",
        "    # Defining the template to generate summary\n",
        "    template = \"\"\"\n",
        "    Write a concise summary of the text, return your responses with 5 lines that cover the key points of the text.\n",
        "    ```{text}```\n",
        "    SUMMARY:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    summary = llm_chain.run(text_chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    return summary"
      ],
      "metadata": {
        "id": "Xxp-YJcp2UHv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8mvs31m26um",
        "outputId": "309468ec-2e14-43c2-b49d-6f9d7b2f2a53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lh7sJKAJ3jlJ",
        "outputId": "304f143b-00b6-4ee1-8d31-2e6879dd0f2c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the energy consumption for your applicat ion can be estimated using the formula\\np = (n processors) × (r watts/processors) × (t hours)\\nwhere p is the energy consumption, n is the number of processors, r is the thermal design\\npower, and t is the application run time. profiling tools are used to ga ther detailed information about the behavior of a parallel program. by\\nunderstanding performance limits, utilizing profiling tools, and optimizing the code based on the\\nprofiling results, developers can enhance the efficiency of parallel applications, lea ding to improved\\nspeedup and overall performance. determine your hardware capabilities:\\nto determine the performance of hardware the following metrics are used :\\n\\uf0b7 the rate at which floating -point operations can be executed (flops/s)\\n\\uf0b7 the rate at which data can be moved between various levels of memory (gb/s)\\n\\uf0b7 the rate at which energy is used by your application (watts)\\nin determining hardware performance and calculating the metrics , we use a mixture of theoretical\\nand empirical measurements . real -world validation is done by empirical measurements , they provide concrete evidence of how\\na system performs under real -world conditions, accounting for various factors like i/o operations,\\nnetwork latency, and concurrency issues. one of the best tools for understanding the hardware you run is the lstopo program (graphical view)\\nand lscpu for text view . this command outputs a graphical view of the hardware on your system. empirical measurement of bandwidth and flop\\nthe empirical bandwidth is the measurement of the fastest rate that memory can be loaded from\\nmain memory into the processor. two different methods are used for measuring the bandwidth: the stream benchmark and the\\nroofline model measured by the empirical roofline toolkit. key differences:\\n\\uf0b7 focus: stream primarily focuses on memory bandwidth, providing quantitative\\nmeasurements. in contrast, the roofline model provides a graphical representation of\\nperformance bottlenecks, considering both computational capabilities and memory\\nbandwidth. \\uf0b7 representation: stream results in a numerical measurement (memory bandwidth in bytes\\nper second), while the roofline model is a graphical representation that helps v isualize\\nperformance limitations. \\uf0b7 insights: stream provides detailed insights into memory subsystem performance, whereas\\nthe roofline model offers a high -level overview of an application's performance efficiency\\nconcerning hardware constraints. we can calculate both a theoretical machine balance (mb t) and an empirical machine balance (mb e)\\nlike so:\\nmb t = f t / b t\\nmb e = f e / b e\\ncharacterizing your application: profiling\\nnow that you have some sense of what performance you can get with the hardware, you need to\\ndetermine what are the performance characteristics of your application. profiling tools :\\nusing call graphs for hot -spot and dependency analysis\\nin the context of parallel programming, call graphs are diagrams that represent the calling\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "chunk_summaries = []\n",
        "torch.cuda.empty_cache()\n",
        "import os\n",
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'\n",
        "for chunk in chunks:\n",
        "    summary = generate_summary(chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(summary)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"done\")\n",
        "    torch.cuda.empty_cache()\n",
        "    # Clear CUDA memory after each iteration\n",
        "\n",
        "    chunk_summaries.append(summary)\n",
        "\n",
        "combined_summary = \"\\n\".join(chunk_summaries)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqPgDq9m3B3M",
        "outputId": "d8f5f60a-b931-4781-d98c-956e0b6218b3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Estimate energy consumption using formula: p = (n processors) × (r watts/processors) × (t hours)\n",
            "    2) Determine hardware capabilities: flop/s, data transfer rate, and energy usage\n",
            "    3) Use empirical measurements to validate the performance of hardware\n",
            "    4) Calculate machine balance (theoretical and empirical)\n",
            "    5) Use profiling tools for hot-spot and dependency analysis\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n",
            "1) Developers can use profiling tools to measure processor clock frequency, energy consumption, and memory usage in parallel applications. \n",
            "    2) Profiling tools like Intel VTune Profiler and AMD CodeXL provide detailed information on performance metrics, including processor clock frequency. \n",
            "    3) Benchmarking suites like SPEC CPU Benchmarks and HPC Challenge Benchmarks can also provide insights into processor clock frequencies. \n",
            "    4) Power measurement tools and hardware devices can be used to measure power consumption. \n",
            "    5) Energy profilers like Intel VTune Profiler can provide insights into energy consumption patterns. \n",
            "    6) Valgrind Massif, Intel VTune Profiler, and OpenMP/MPI memory profilers are some of the tools that can be used to track memory usage during runtime.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=\" \".join(clustered_sentences[1])\n",
        "print(s)\n"
      ],
      "metadata": {
        "id": "EgK2CqwdlGTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rYJQqfvOlGbl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "   chunk_size=3096, chunk_overlap=0\n",
        ")\n",
        "chunks = text_splitter.split_text(s)\n",
        "# docs = text_splitter.create_documents([text])\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "9VLO8QmTlGku"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate,  LLMChain\n",
        "def generate_summary(text_chunk):\n",
        "    # Defining the template to generate summary\n",
        "    template = \"\"\"\n",
        "    Write a concise summary of the text, return your responses with 5 lines that cover the key points of the text.\n",
        "    ```{text}```\n",
        "    SUMMARY:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    summary = llm_chain.run(text_chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    return summary"
      ],
      "metadata": {
        "id": "WfA0YSPMlafM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "id": "lfDFt8rIlbct",
        "outputId": "166e67ec-d8e4-49ec-8c40-6b4e6aab420c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "chunk_summaries = []\n",
        "torch.cuda.empty_cache()\n",
        "import os\n",
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'\n",
        "for chunk in chunks:\n",
        "    summary = generate_summary(chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(summary)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"done\")\n",
        "    torch.cuda.empty_cache()\n",
        "    # Clear CUDA memory after each iteration\n",
        "\n",
        "    chunk_summaries.append(summary)\n",
        "\n",
        "combined_summary = \"\\n\".join(chunk_summaries)\n"
      ],
      "metadata": {
        "id": "2EqceQellgY2",
        "outputId": "899573b9-f481-42f1-a1fe-177c489aa928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Parallel computing can be done in serial way or parallel way\n",
            "    2. Serial computing is traditional computing where tasks are executed sequentially using a single processor\n",
            "    3. Parallel computing divides the task into smaller sub -tasks that can be processed simultaneously\n",
            "    4. Parallel computing can lead to significant improvements in computational speed and efficiency\n",
            "    5. Parallel computing involves identifying and exposing parallelism in algorithms, expressing this in software, and understanding the costs, benefits, and limitations of the chosen implementation.\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   \n",
            "done\n",
            "1. Parallel computing can improve run times by utilizing multiple processors or computing resources to solve a problem. \n",
            "    2. Larger problem sizes can be handled with more compute nodes. \n",
            "    3. Energy efficiency can be achieved by optimizing energy use while achieving better computational performance. \n",
            "    4. Scalability can be improved by adding more processors. \n",
            "    5. Parallel computing can reduce costs by taking advantage of cost reductions in technology.\n",
            "    6. Parallel computing is used in scientific simulations, big data processing, and video and image processing. \n",
            "    7. Fundamental laws, such as Amdahl's Law and Gustafson's Law, provide insight into the limitations and possibilities of parallel processing. \n",
            "    8. Speedup is a measure of how much faster a parallel algorithm can complete a task compared to a serial implementation. \n",
            "    9. The speedup can be calculated using the formula: s=tserial / tparallel.\n",
            "\n",
            "\n",
            "done\n",
            "1. Amdahl's law states that the speedup of a parallel algorithm is limited by the sequential fraction of the algorithm.\n",
            "    2. Gustafson's law states that as the problem size increases, the impact of the parallelizable portion of the program becomes more significant, leading to better scalability.\n",
            "    3. Strong scaling measures the performance of a parallel algorithm or application when the workload is increased.\n",
            "    4. Weak scaling measures the performance of a parallel algorithm or application when the number of processors is increased.\n",
            "    5. The maximum speedup achievable according to Amdahl's law is approximately 3.57 times faster compared to the sequential execution.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n",
            "1. Strong scaling measures how execution time decreases as the number of processors increases for a fixed problem size. \n",
            "    2. Weak scaling measures how execution time changes as both the problem size and number of processors increase proportionally. \n",
            "    3. Strong scaling aims to reduce execution time for a fixed problem size by utilizing more processors. \n",
            "    4. Weak scaling aims to maintain a constant workload per processor as the problem size and number of processors increase. \n",
            "    5. Parallel approaches are categorized by Flynn as data-driven, task-driven, and goal-driven. \n",
            "\n",
            "\n",
            "\n",
            "done\n",
            "1) Flynn's taxonomy categorizes parallel computing architectures based on the number of instruction and data streams.\n",
            "    2) Parallel strategies include data parallelism, task parallelism, and bucket brigade parallelism.\n",
            "    3) Parallel speedup measures the performance improvement achieved by parallel processing.\n",
            "    4) Comparative speedup compares the performance of different parallel architectures or implementations.\n",
            "    5) Flynn's taxonomy highlights the importance of parallelism in modern computing and provides a framework for understanding and categorizing different types of parallel architectures.\n",
            "done\n",
            "1. Parallel computing involves breaking up work into smaller tasks and processing them simultaneously across multiple processors.\n",
            "    2. There are various parallel computing approaches, including process-based, data-based, and model-based.\n",
            "    3. Parallel programming models involve exposing parallelization, determining the best technique, and explicitly directing its operation.\n",
            "    4. Common parallelization techniques include message passing, threads, processes, and offloading to GPUs.\n",
            "    5. Performance limits and profiling are crucial steps in optimizing parallel program execution.\n",
            "    6. Understanding performance limits helps design efficient algorithms, optimize software, and choose appropriate hardware configurations.\n",
            "    7. Hot spots in parallel programs can be optimized for better performance.\n",
            "\n",
            "   .\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n",
            "\n",
            "    - Parallel algorithms are designed to run on multiple processors or cores.\n",
            "    \n",
            "    - Parallel patterns are like blueprints for solving specific types of problems.\n",
            "    \n",
            "    - Parallel algorithms are based on the \"divide and conquer\" pattern.\n",
            "    \n",
            "    - Algorithm analysis is used to compare different algorithms used to solve the same problem.\n",
            "    \n",
            "    - Algorithmic complexity is one way to evaluate algorithms.\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "\n",
            "   .\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=\" \".join(clustered_sentences[3])\n",
        "# print(s)\n",
        "torch.cuda.empty_cache()\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "   chunk_size=3096, chunk_overlap=0\n",
        ")\n",
        "chunks = text_splitter.split_text(s)\n",
        "# docs = text_splitter.create_documents([text])\n",
        "torch.cuda.empty_cache()\n",
        "from langchain import PromptTemplate,  LLMChain\n",
        "def generate_summary(text_chunk):\n",
        "    # Defining the template to generate summary\n",
        "    template = \"\"\"\n",
        "    Write a concise summary of the text, return your responses with 5 lines that cover the key points of the text.\n",
        "    ```{text}```\n",
        "    SUMMARY:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    summary = llm_chain.run(text_chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    return summary\n",
        "\n",
        "len(chunks)\n",
        "import torch\n",
        "chunk_summaries = []\n",
        "torch.cuda.empty_cache()\n",
        "import os\n",
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'\n",
        "for chunk in chunks:\n",
        "    summary = generate_summary(chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(summary)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"done\")\n",
        "    torch.cuda.empty_cache()\n",
        "    # Clear CUDA memory after each iteration\n",
        "\n",
        "    chunk_summaries.append(summary)\n",
        "\n",
        "combined_summary = \"\\n\".join(chunk_summaries)\n"
      ],
      "metadata": {
        "id": "BU7NtnO8mgKC",
        "outputId": "61fea798-5fc5-41ee-def7-1791f55fe4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Computing is the use of computers to perform tasks.\n",
            "    2. Serial computing is when each task waits for the previous one to finish.\n",
            "    3. Parallel computing is when multiple processors work on different parts of the dataset simultaneously.\n",
            "    4. Parallel computing can be more efficient than serial computing because it allows multiple tasks to be completed at the same time.\n",
            "    5. Serial computing does not scale well because it relies on a single processor.\n",
            "    ```\n",
            "\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Single Instruction Single Data (SISD) - a single processor executes a single instruction stream on a single data stream.\n",
            "    2. Single Instruction Multiple Data (SIMD) - a single processor executes the same instruction on multiple data streams in parallel.\n",
            "    3. Multiple Instruction Single Data (MISD) - multiple processors execute different instructions on the same data stream.\n",
            "    4. Multiple Instruction Multiple Data (MIMD) - multiple processors execute different instructions on different data streams.\n",
            "    5. Distributed Memory Architecture - multiple processors or nodes in a cluster have their own private memory, and data sharing is achieved explicitly through message passing.\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Parallelism in shared memory architecture refers to techniques that allow multiple threads or processes to run concurrently on the same node, sharing the same memory space to perform computations.\n",
            "2) Vector units, also known as vector processors, are specialized hardware units that can perform multiple operations with a single instruction, making them useful for processing large sets of data elements.\n",
            "3) An accelerator device is a specialized hardware component designed to perform specific computational tasks efficiently, often used in conjunction with a CPU.\n",
            "4) A general heterogeneous parallel architecture model involves dividing a task into multiple processes or threads that run independently on separate computing nodes or cores, with the OS controlling the placement of the processes and allocating memory for each process from the node's main memory.\n",
            "5) Thread-based parallelization involves dividing a task into multiple threads that share the same memory space within a single process, allowing them to run concurrently on multiple CPU cores.\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Shared Memory: \n",
            "        - Used in multi -core processors and SMP systems\n",
            "        - Some memory is shared between threads\n",
            "    2) Vectorization: \n",
            "        - Multiple operations with one instruction\n",
            "        - Takes advantage of Simd capabilities in modern processors\n",
            "    3) Stream Processing: \n",
            "        - Data is continuously processed as it is generated or ingested\n",
            "        - Specialized processors accelerate the analysis and manipulation of data streams\n",
            "    4) Offloading to GPU: \n",
            "        - Data and compute kernel are offloaded to the GPU and its streaming multiprocessors\n",
            "        - Processed data transfers back to the CPU for file I/O or other work\n",
            "    5) Limits:\n",
            "        - Flops (floating -point operations)\n",
            "        - Ops (operations) that include all types of computer instructions\n",
            "\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    - Memory bandwidth: the rate at which data is transferred\n",
            "    \n",
            "    - Memory latency: the time required for the first byte or word of data to be transferred\n",
            "    \n",
            "    - Instruction queue: (instruction cache)\n",
            "    \n",
            "    - Networks:\n",
            "    \n",
            "    - Disk\n",
            "    \n",
            "    - Machine balance: number of flops executed / memory bandwidth\n",
            "    \n",
            "    - Arithmetic intensity: number of flops executed per memory operation\n",
            "    \n",
            "    - Non-contiguous memory access: the manner in which data elements are accessed in memory\n",
            "    \n",
            "    - Stride: the distance between each element in memory\n",
            "    \n",
            "    - Clock speed: the number of cycles the processor can execute per second\n",
            "    \n",
            "    - Flops per cycle per core: the number of floating-point operations a core can perform in a single clock cycle\n",
            "    \n",
            "    - Theoretical flops: the number of flops a system can perform per second\n",
            "    \n",
            "    - Theoretical memory bandwidth: the theoretical data transfer rate of the main memory\n",
            "    \n",
            "    - Data transfer rate: the number of bits per second transferred over a given period\n",
            "    \n",
            "    - Memory channels: the number of independent channels for transferring data between the processor and main memory\n",
            "    \n",
            "    - Bytes per access: the number of bytes transferred per memory access\n",
            "    \n",
            "    - Sockets: the number of sockets on a motherboard\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) The socket is the location where the processor is inserted, usually on a motherboard.\n",
            "    2) Most motherboards have a single socket, but some have dual sockets for high-performance computing.\n",
            "    3) Two processors can be installed on a dual-socket motherboard, increasing processing power and memory bandwidth.\n",
            "    4) The time it takes to retrieve a single byte of memory from main memory can be around 400 clock cycles.\n",
            "    5) The machine balance between FLOPs and memory bandwidth is calculated by dividing FLOPs by memory bandwidth.\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "   .\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=\" \".join(clustered_sentences[2])\n",
        "# print(s)\n",
        "torch.cuda.empty_cache()\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "   chunk_size=3096, chunk_overlap=0\n",
        ")\n",
        "chunks = text_splitter.split_text(s)\n",
        "len(chunks)\n",
        "# docs = text_splitter.create_documents([text])\n",
        "torch.cuda.empty_cache()\n",
        "from langchain import PromptTemplate,  LLMChain\n",
        "def generate_summary(text_chunk):\n",
        "    # Defining the template to generate summary\n",
        "    template = \"\"\"\n",
        "    Write a concise summary of the text, return your responses with 5 lines that cover the key points of the text.\n",
        "    ```{text}```\n",
        "    SUMMARY:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "    summary = llm_chain.run(text_chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    return summary\n",
        "\n",
        "\n",
        "import torch\n",
        "chunk_summaries = []\n",
        "torch.cuda.empty_cache()\n",
        "import os\n",
        "\n",
        "# Set the max_split_size_mb environment variable\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:50'\n",
        "for chunk in chunks:\n",
        "    summary = generate_summary(chunk)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(summary)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"done\")\n",
        "    torch.cuda.empty_cache()\n",
        "    # Clear CUDA memory after each iteration\n",
        "\n",
        "    chunk_summaries.append(summary)\n",
        "\n",
        "combined_summary = \"\\n\".join(chunk_summaries)\n"
      ],
      "metadata": {
        "id": "x1nbqB5gnrPt",
        "outputId": "48fec3ca-a1fb-489b-cbce-eae698e0714d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Data parallelism is a strategy used to speed up processing tasks by dividing them into smaller sub-tasks and processing them simultaneously.\n",
            "    2. Flynn's Taxonomy is a classification system for computer architectures based on their ability to perform different types of operations.\n",
            "    3. Data parallelism is used in applications where the same operation can be applied to different pieces of data independently.\n",
            "    4. In a task parallelism scenario, each task is processed concurrently, with each task performing a different operation.\n",
            "    5. In a main-worker approach, one processor schedules and distributes tasks for all workers, and each worker checks for the next work item as it returns the previous completed task.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b9d388eaa1c1>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTORCH_CUDA_ALLOC_CONF'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_split_size_mb:50'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-b9d388eaa1c1>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(text_chunk)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mllm_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             outputs = (\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    515\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 )\n\u001b[1;32m    665\u001b[0m             ]\n\u001b[0;32m--> 666\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             output = (\n\u001b[0;32m--> 540\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    541\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# Process each response in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 )\n\u001b[0;32m-> 1121\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;31m# reuse k, v, self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 18.81 MiB is free. Process 2959 has 14.73 GiB memory in use. Of the allocated memory 13.74 GiB is allocated by PyTorch, and 191.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba8aa3c837b14885b35579e4c885a73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78d8d13099324d13945342a280aa9a49",
              "IPY_MODEL_f6fb97b80a464613948ebfa63af3334a",
              "IPY_MODEL_48de420e582c4a278785416584c868d6"
            ],
            "layout": "IPY_MODEL_f465282061ff444faea61579ba088315"
          }
        },
        "78d8d13099324d13945342a280aa9a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b00ce229f944fc3844e5d72b51ead79",
            "placeholder": "​",
            "style": "IPY_MODEL_c00a53d07725457394181dfcaf1294be",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f6fb97b80a464613948ebfa63af3334a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0782cbade2f4ff3a6c222ddf78512de",
            "max": 1567,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_088db205eea7448781a90a2d8eb53198",
            "value": 1567
          }
        },
        "48de420e582c4a278785416584c868d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d5be8a84a941918635c108421fb693",
            "placeholder": "​",
            "style": "IPY_MODEL_304292dda28f4ed59794dc03c48e7b51",
            "value": " 1.57k/1.57k [00:00&lt;00:00, 104kB/s]"
          }
        },
        "f465282061ff444faea61579ba088315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b00ce229f944fc3844e5d72b51ead79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00a53d07725457394181dfcaf1294be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0782cbade2f4ff3a6c222ddf78512de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088db205eea7448781a90a2d8eb53198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29d5be8a84a941918635c108421fb693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304292dda28f4ed59794dc03c48e7b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e65a9bc0e6341a284ed41cf5403401e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25fd421e2e5d433f8c7afeb43b0d56e4",
              "IPY_MODEL_b53cdcfaa6284ba093191f567fd1492d",
              "IPY_MODEL_e8080ac9f5fd4772a95568a208ebcd3d"
            ],
            "layout": "IPY_MODEL_2d73c7e3b05e4275a837dcd02fcfc56d"
          }
        },
        "25fd421e2e5d433f8c7afeb43b0d56e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a6adb970ae4b01808d29966317f46f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce3bfd833df5439cb43687275ca3e097",
            "value": "tokenizer.json: 100%"
          }
        },
        "b53cdcfaa6284ba093191f567fd1492d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e8803b1cccf4a6e91800cbe3de80ae7",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecda5a77fbfe437ab6fdb290996dc2f1",
            "value": 1842767
          }
        },
        "e8080ac9f5fd4772a95568a208ebcd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4b2478c88ba4f74bee7fbe72de98248",
            "placeholder": "​",
            "style": "IPY_MODEL_00b70f9383314139ac427a26629e420c",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 7.05MB/s]"
          }
        },
        "2d73c7e3b05e4275a837dcd02fcfc56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a6adb970ae4b01808d29966317f46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3bfd833df5439cb43687275ca3e097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e8803b1cccf4a6e91800cbe3de80ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecda5a77fbfe437ab6fdb290996dc2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4b2478c88ba4f74bee7fbe72de98248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b70f9383314139ac427a26629e420c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7090ec5683a48ef9553f598a11ed6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bd0b9542f9a4cfa974722c247f6ece0",
              "IPY_MODEL_f20ddd7868a84e40a7954063c952a4d2",
              "IPY_MODEL_56abc4ccd8054dc18ebd7d141af54222"
            ],
            "layout": "IPY_MODEL_9752074130a1441cbe350d5108d6ec4b"
          }
        },
        "9bd0b9542f9a4cfa974722c247f6ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1955c15c35f42c28f85b6917b67a53f",
            "placeholder": "​",
            "style": "IPY_MODEL_ea558a89c5204ee0bb962a0d9a572b37",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f20ddd7868a84e40a7954063c952a4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a50f9c6400bb4bcabdc225fc01b4a3c3",
            "max": 437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15574030ede44d59a1b922a158b8fa76",
            "value": 437
          }
        },
        "56abc4ccd8054dc18ebd7d141af54222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db419750178a4ce88795795fa9d4568b",
            "placeholder": "​",
            "style": "IPY_MODEL_b09a75d90ceb4568bc4a6b336b8758c7",
            "value": " 437/437 [00:00&lt;00:00, 29.7kB/s]"
          }
        },
        "9752074130a1441cbe350d5108d6ec4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1955c15c35f42c28f85b6917b67a53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea558a89c5204ee0bb962a0d9a572b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a50f9c6400bb4bcabdc225fc01b4a3c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15574030ede44d59a1b922a158b8fa76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db419750178a4ce88795795fa9d4568b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09a75d90ceb4568bc4a6b336b8758c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9060a88461544329097b37afb90651f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d9ffbe4f3a947989e15a1984b45c89f",
              "IPY_MODEL_423723c7325f4712bfeb85a3ffdd6a2b",
              "IPY_MODEL_c490ba341984466e9e36b15091fea74e"
            ],
            "layout": "IPY_MODEL_d6eac16872e34c5ea014709b742ae9ef"
          }
        },
        "3d9ffbe4f3a947989e15a1984b45c89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33ac625e2d64948b771661f0b57023a",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d8f36b2ac04aba81ada4a41defca35",
            "value": "config.json: 100%"
          }
        },
        "423723c7325f4712bfeb85a3ffdd6a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a6d4762508481d9384251fbae5151b",
            "max": 630,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c71bde575dd4840a4a27cfbcf151cc7",
            "value": 630
          }
        },
        "c490ba341984466e9e36b15091fea74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855503613bc644babcb778b61bb79e51",
            "placeholder": "​",
            "style": "IPY_MODEL_140a750fae3d47cfb491f6c5f7e35eed",
            "value": " 630/630 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "d6eac16872e34c5ea014709b742ae9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33ac625e2d64948b771661f0b57023a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d8f36b2ac04aba81ada4a41defca35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a6d4762508481d9384251fbae5151b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c71bde575dd4840a4a27cfbcf151cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "855503613bc644babcb778b61bb79e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140a750fae3d47cfb491f6c5f7e35eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331d5c23847f4745b2167da765198ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f95058c7fee5458293cfdaf5b7c8b10c",
              "IPY_MODEL_2763e2f5c42f4b149a37cd23eaf18677",
              "IPY_MODEL_02fd78e129364822b2c24fbee6c037f7"
            ],
            "layout": "IPY_MODEL_7493b4cb44af4ed5b3b9c64876bdfab9"
          }
        },
        "f95058c7fee5458293cfdaf5b7c8b10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96be09472ad64a468aefd0b43c99ca65",
            "placeholder": "​",
            "style": "IPY_MODEL_9dccfed5a1cd42bdac89d3b2a7cf68f6",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "2763e2f5c42f4b149a37cd23eaf18677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9de020ddb6742218f6e2112f281babc",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2221dbe36d248aebaee8c8b9ff9a649",
            "value": 26788
          }
        },
        "02fd78e129364822b2c24fbee6c037f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d045d436c64e2a92b75fc6a8c51f40",
            "placeholder": "​",
            "style": "IPY_MODEL_5459d1f8ac8640b0bedb5adbdd0824f5",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.35MB/s]"
          }
        },
        "7493b4cb44af4ed5b3b9c64876bdfab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96be09472ad64a468aefd0b43c99ca65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dccfed5a1cd42bdac89d3b2a7cf68f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9de020ddb6742218f6e2112f281babc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2221dbe36d248aebaee8c8b9ff9a649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7d045d436c64e2a92b75fc6a8c51f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5459d1f8ac8640b0bedb5adbdd0824f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddbbd456bffb4ff0a488ce2a3df13222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a758a3a400c4ef8924a9cb2644fb397",
              "IPY_MODEL_9f87901282594b7cbb13a621a62ab6f1",
              "IPY_MODEL_8b190f02ef1847b3aee33547748ea2ba"
            ],
            "layout": "IPY_MODEL_709e2e30309a4b4f908084a11e74d286"
          }
        },
        "2a758a3a400c4ef8924a9cb2644fb397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195fa9ac9d8140d4aff78d81abe4829d",
            "placeholder": "​",
            "style": "IPY_MODEL_08c58b1861be41a990b777daa018eef6",
            "value": "Downloading shards: 100%"
          }
        },
        "9f87901282594b7cbb13a621a62ab6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f990061922a8484d9788a687f25a33de",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e71f5480ff402b873372e8bd047a38",
            "value": 2
          }
        },
        "8b190f02ef1847b3aee33547748ea2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39c29c41e144cc4b24c26f32e31a77b",
            "placeholder": "​",
            "style": "IPY_MODEL_822278b5294149aa81c88d16187b4a9e",
            "value": " 2/2 [05:55&lt;00:00, 162.61s/it]"
          }
        },
        "709e2e30309a4b4f908084a11e74d286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195fa9ac9d8140d4aff78d81abe4829d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c58b1861be41a990b777daa018eef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f990061922a8484d9788a687f25a33de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e71f5480ff402b873372e8bd047a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f39c29c41e144cc4b24c26f32e31a77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822278b5294149aa81c88d16187b4a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8eb8e2f986444e38612953e855a1f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_872006a114304cb095918a0bd50f8e2f",
              "IPY_MODEL_f625e39f257a42258ffca3753acecc9d",
              "IPY_MODEL_dff34ad65c3c4963aaeeab7616daf9dc"
            ],
            "layout": "IPY_MODEL_7f960056efdd4501be0b6d9328ade427"
          }
        },
        "872006a114304cb095918a0bd50f8e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7fa6df0a9bd480392fd51cfc56b1b62",
            "placeholder": "​",
            "style": "IPY_MODEL_66f7228aa1c9437e933059b477ad3522",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "f625e39f257a42258ffca3753acecc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4259477aab47898449db1940bc750e",
            "max": 9976638373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ef0f583e6644a1891daa46da8ce8fd5",
            "value": 9976638373
          }
        },
        "dff34ad65c3c4963aaeeab7616daf9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0ef9f4788d4bedb335b63a61dc679c",
            "placeholder": "​",
            "style": "IPY_MODEL_acc80baab5184bcbbf1d6124b8db3223",
            "value": " 9.98G/9.98G [04:21&lt;00:00, 30.0MB/s]"
          }
        },
        "7f960056efdd4501be0b6d9328ade427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fa6df0a9bd480392fd51cfc56b1b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f7228aa1c9437e933059b477ad3522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4259477aab47898449db1940bc750e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef0f583e6644a1891daa46da8ce8fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab0ef9f4788d4bedb335b63a61dc679c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc80baab5184bcbbf1d6124b8db3223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed8ba9d28d5a45829122a550c726002e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1effc167f6d424ca222da0a7a875436",
              "IPY_MODEL_f44439ccfbdb443d891b577bff9c0ff7",
              "IPY_MODEL_6b17003098ac440c972c1edb355d2ec7"
            ],
            "layout": "IPY_MODEL_d49d866edee74c0ca973a49776959d95"
          }
        },
        "d1effc167f6d424ca222da0a7a875436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_955004c55c424085b8f9346dd962ecd0",
            "placeholder": "​",
            "style": "IPY_MODEL_15d18b6b9d604065ba17cf16ec75d4a9",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "f44439ccfbdb443d891b577bff9c0ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6024061a054cedbdb866c3585f48fe",
            "max": 3500317102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f34e57064d4fd09a60ae2554a9c748",
            "value": 3500317102
          }
        },
        "6b17003098ac440c972c1edb355d2ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd3c1f77ad549e4a81a6edf0d86b6a7",
            "placeholder": "​",
            "style": "IPY_MODEL_ee624b8c249d4aeca04fb8f41e9d1731",
            "value": " 3.50G/3.50G [01:24&lt;00:00, 43.2MB/s]"
          }
        },
        "d49d866edee74c0ca973a49776959d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955004c55c424085b8f9346dd962ecd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d18b6b9d604065ba17cf16ec75d4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff6024061a054cedbdb866c3585f48fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f34e57064d4fd09a60ae2554a9c748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cd3c1f77ad549e4a81a6edf0d86b6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee624b8c249d4aeca04fb8f41e9d1731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc81683b9c054317bb38df7f5d0daf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1923c3c32ead465ab871bdf15568434c",
              "IPY_MODEL_94d27b4ee56f4c6487d68d984151ae75",
              "IPY_MODEL_5daff8b92c2a4b87896449d8fb3f4504"
            ],
            "layout": "IPY_MODEL_2d990a598f454862a1f8937017ef8524"
          }
        },
        "1923c3c32ead465ab871bdf15568434c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784ea746282d4389b03b631ce1703887",
            "placeholder": "​",
            "style": "IPY_MODEL_d5700c3910af4ae2959a8744076c3958",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "94d27b4ee56f4c6487d68d984151ae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc0f7a5cb90f458291d8402c8b90232d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba772723287b476d823b802663688fee",
            "value": 2
          }
        },
        "5daff8b92c2a4b87896449d8fb3f4504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_000c79839ef14fa19d85e2ecb68557cf",
            "placeholder": "​",
            "style": "IPY_MODEL_20e378b9064c44a584156b00828a326b",
            "value": " 2/2 [01:11&lt;00:00, 32.45s/it]"
          }
        },
        "2d990a598f454862a1f8937017ef8524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784ea746282d4389b03b631ce1703887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5700c3910af4ae2959a8744076c3958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc0f7a5cb90f458291d8402c8b90232d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba772723287b476d823b802663688fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "000c79839ef14fa19d85e2ecb68557cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20e378b9064c44a584156b00828a326b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d7ad4a0593f4142bd4f6486f17d3e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9002b3913645c1ba60bf3f87775994",
              "IPY_MODEL_0abad186d2ab4ed08ee3eed7c7c85b49",
              "IPY_MODEL_7e67f77d1c634a398278c7b02a415a82"
            ],
            "layout": "IPY_MODEL_b6ae04cf11a84b40a8c8caa34f48f06e"
          }
        },
        "7b9002b3913645c1ba60bf3f87775994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c40e59923e4e7e96f8424036d35dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_4dc2b5cfe95640d7b1143dfa0a2b6e13",
            "value": "generation_config.json: 100%"
          }
        },
        "0abad186d2ab4ed08ee3eed7c7c85b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba0b7538e0046e2bc43a845fac510cf",
            "max": 183,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c42d8ff330ed4dd492e5b27203faeafc",
            "value": 183
          }
        },
        "7e67f77d1c634a398278c7b02a415a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5a12f0ddc2465bb245ec553419ca18",
            "placeholder": "​",
            "style": "IPY_MODEL_85d42786d2234386bf50d7744fd04cc1",
            "value": " 183/183 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "b6ae04cf11a84b40a8c8caa34f48f06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52c40e59923e4e7e96f8424036d35dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc2b5cfe95640d7b1143dfa0a2b6e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eba0b7538e0046e2bc43a845fac510cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42d8ff330ed4dd492e5b27203faeafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f5a12f0ddc2465bb245ec553419ca18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d42786d2234386bf50d7744fd04cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8fa5c315a964fa085e1a62f7848b7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_510d04c062af4848b701e33e751e33f0",
              "IPY_MODEL_31a32a91f0054d23b75d94ce6524baa8",
              "IPY_MODEL_8538280fa68542729f00389ca227266c"
            ],
            "layout": "IPY_MODEL_6fe83f42266742a0b91e0ab9f7acce6c"
          }
        },
        "510d04c062af4848b701e33e751e33f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fad7837f0054fc9b5ed0fbb3acd8793",
            "placeholder": "​",
            "style": "IPY_MODEL_ad429c3a13834707852c4ab582e7bedb",
            "value": ".gitattributes: 100%"
          }
        },
        "31a32a91f0054d23b75d94ce6524baa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6894fda37644288a923fd79e3a9afb0",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7937fc500a4d7d812b157fe8b597dc",
            "value": 1175
          }
        },
        "8538280fa68542729f00389ca227266c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852179bc137a4c4fa83c37eb418d993b",
            "placeholder": "​",
            "style": "IPY_MODEL_dac291da8fc84104a09e394b4eef28b7",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 77.2kB/s]"
          }
        },
        "6fe83f42266742a0b91e0ab9f7acce6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fad7837f0054fc9b5ed0fbb3acd8793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad429c3a13834707852c4ab582e7bedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6894fda37644288a923fd79e3a9afb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7937fc500a4d7d812b157fe8b597dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "852179bc137a4c4fa83c37eb418d993b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac291da8fc84104a09e394b4eef28b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "959ee251f360409b87f8d67bb59ba20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09c780657fd347ac88afe97a0ba9cb82",
              "IPY_MODEL_71a03b0e4f794603a0b91ebd97d420eb",
              "IPY_MODEL_2e2f54571a654da39e2a8004daf3124c"
            ],
            "layout": "IPY_MODEL_f1bc9029521c45f6b8c8f0eb00fd7d4f"
          }
        },
        "09c780657fd347ac88afe97a0ba9cb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2fdf3cce0ff40e39aff780e81854822",
            "placeholder": "​",
            "style": "IPY_MODEL_47b51fe5d64e46b896811f3d96704029",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "71a03b0e4f794603a0b91ebd97d420eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749c1cf8fd464a1da528855d40fdc70d",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf37d036c3d94d339f4f09c47a0c9795",
            "value": 190
          }
        },
        "2e2f54571a654da39e2a8004daf3124c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d0a4fc1445465f8a430386dc1f4f08",
            "placeholder": "​",
            "style": "IPY_MODEL_fc3860ae466c49a18d037cdea8178976",
            "value": " 190/190 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "f1bc9029521c45f6b8c8f0eb00fd7d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2fdf3cce0ff40e39aff780e81854822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b51fe5d64e46b896811f3d96704029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "749c1cf8fd464a1da528855d40fdc70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf37d036c3d94d339f4f09c47a0c9795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89d0a4fc1445465f8a430386dc1f4f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc3860ae466c49a18d037cdea8178976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68cf3b79a732432fa1faa9d28c66662f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3f094dab0f148919d30af40f23c66f7",
              "IPY_MODEL_28ae4007a25a4c6e8484d1a3974fab48",
              "IPY_MODEL_55218abcd81e4955be21a6634b01b1ff"
            ],
            "layout": "IPY_MODEL_a211a26cdf4d44a4a1a76448a51f15a3"
          }
        },
        "e3f094dab0f148919d30af40f23c66f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4335c613f18d4372b286dcb0565695af",
            "placeholder": "​",
            "style": "IPY_MODEL_5e4ec3db91fe4970a9483aa00cff1a7a",
            "value": "README.md: 100%"
          }
        },
        "28ae4007a25a4c6e8484d1a3974fab48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a16030691b4e4d358bbda4aba0811ab5",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5de3c66469334089a06a917c94403233",
            "value": 10610
          }
        },
        "55218abcd81e4955be21a6634b01b1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dec7b7c78f849c7891bc2b5ed30940c",
            "placeholder": "​",
            "style": "IPY_MODEL_51f573ffef244df08d99800e683aba62",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 602kB/s]"
          }
        },
        "a211a26cdf4d44a4a1a76448a51f15a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4335c613f18d4372b286dcb0565695af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4ec3db91fe4970a9483aa00cff1a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16030691b4e4d358bbda4aba0811ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de3c66469334089a06a917c94403233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dec7b7c78f849c7891bc2b5ed30940c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f573ffef244df08d99800e683aba62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa2e228e85c74a19b4f30d975ae6c7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2405cc641a9b41e9a0e2a7200226230d",
              "IPY_MODEL_e884b462959642179c48dcc8cdeae504",
              "IPY_MODEL_c6fac57b36344359873529383d16c42e"
            ],
            "layout": "IPY_MODEL_8554b34309114b53889872a969f8eaf6"
          }
        },
        "2405cc641a9b41e9a0e2a7200226230d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e63b407151b4f178a9302b5b692b917",
            "placeholder": "​",
            "style": "IPY_MODEL_31c69e0521d3401883882a8957efcef4",
            "value": "config.json: 100%"
          }
        },
        "e884b462959642179c48dcc8cdeae504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2468a313d85645eaa9f08f21b1aa55ab",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b9ba9f02dc54a399672e3bea97111b5",
            "value": 612
          }
        },
        "c6fac57b36344359873529383d16c42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b863e3667244380910f45d5a6a33b6e",
            "placeholder": "​",
            "style": "IPY_MODEL_b153337ee55b4a4691ad94932aed8f01",
            "value": " 612/612 [00:00&lt;00:00, 43.7kB/s]"
          }
        },
        "8554b34309114b53889872a969f8eaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e63b407151b4f178a9302b5b692b917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c69e0521d3401883882a8957efcef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2468a313d85645eaa9f08f21b1aa55ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9ba9f02dc54a399672e3bea97111b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b863e3667244380910f45d5a6a33b6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b153337ee55b4a4691ad94932aed8f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2698049f8fbe4b0bad9e24378ac817ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81bece39f8c4ae98b47ecaf431529ac",
              "IPY_MODEL_33bf7d855877487383e5d9574daa572f",
              "IPY_MODEL_2e59a7bbe65d42d7b6c938b58d8acc80"
            ],
            "layout": "IPY_MODEL_3667c3e244824e9b81dde6c28e7b33fe"
          }
        },
        "c81bece39f8c4ae98b47ecaf431529ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d1549485b7a4f51a885eba58bed5aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_a40e0892d6bf4f688b2c9459ce05ac56",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "33bf7d855877487383e5d9574daa572f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5934bd744ddf465098c48f87587a4e84",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3ec53ee37a14677bf78df08b48df8ce",
            "value": 116
          }
        },
        "2e59a7bbe65d42d7b6c938b58d8acc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c89e4e70674ebc8210bf4ab0add059",
            "placeholder": "​",
            "style": "IPY_MODEL_0080d62126844f19b800e6a08a8d58ef",
            "value": " 116/116 [00:00&lt;00:00, 8.60kB/s]"
          }
        },
        "3667c3e244824e9b81dde6c28e7b33fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1549485b7a4f51a885eba58bed5aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40e0892d6bf4f688b2c9459ce05ac56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5934bd744ddf465098c48f87587a4e84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ec53ee37a14677bf78df08b48df8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17c89e4e70674ebc8210bf4ab0add059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0080d62126844f19b800e6a08a8d58ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd6ee8a0c7a4716bdb405976c8d5e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d622152fc618498a903cb9d561cf8c68",
              "IPY_MODEL_4137995ff6224239b08a7ae7930cb7a6",
              "IPY_MODEL_ba7b356aad8c49b09ee5533433f3fedc"
            ],
            "layout": "IPY_MODEL_6974964735ff4fc29dc9c6047e902105"
          }
        },
        "d622152fc618498a903cb9d561cf8c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e9172a95d94406bc8cd0cd5c23ac59",
            "placeholder": "​",
            "style": "IPY_MODEL_6b7a74b545774891853e05d165ce9cf7",
            "value": "data_config.json: 100%"
          }
        },
        "4137995ff6224239b08a7ae7930cb7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60e86a08ad3c41eb87a3f70abdd2757e",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee1d12d44d3041bdb2c2efb1c48c1182",
            "value": 39265
          }
        },
        "ba7b356aad8c49b09ee5533433f3fedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_355a902372f1468b8d94c5f2ece0c53e",
            "placeholder": "​",
            "style": "IPY_MODEL_7352013ac4bd47feb99297f37d030b30",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "6974964735ff4fc29dc9c6047e902105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e9172a95d94406bc8cd0cd5c23ac59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7a74b545774891853e05d165ce9cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60e86a08ad3c41eb87a3f70abdd2757e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1d12d44d3041bdb2c2efb1c48c1182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "355a902372f1468b8d94c5f2ece0c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7352013ac4bd47feb99297f37d030b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98f9c9af95c5414e99952240ef4a4290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9821bb8b2a84d5e83cbbf1f82e52526",
              "IPY_MODEL_547a376b0ef14cc787fc7254e1f4117f",
              "IPY_MODEL_eb3717f4aeae4daba81509849434af8f"
            ],
            "layout": "IPY_MODEL_255900b25a52428ebae78952ed45913e"
          }
        },
        "a9821bb8b2a84d5e83cbbf1f82e52526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6ba39932555438f8ff362b18c67a82f",
            "placeholder": "​",
            "style": "IPY_MODEL_b5015202578f4965afb875148854c19c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "547a376b0ef14cc787fc7254e1f4117f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce275d58b21041539f574c442bdf770e",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a94e63ca1801461cb71d4980c705ddb2",
            "value": 90888945
          }
        },
        "eb3717f4aeae4daba81509849434af8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c8ff1ce271b4e8db2a3dbfab0d94e02",
            "placeholder": "​",
            "style": "IPY_MODEL_041bdd8faa8a456d94b1cf2f33ab296b",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 142MB/s]"
          }
        },
        "255900b25a52428ebae78952ed45913e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ba39932555438f8ff362b18c67a82f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5015202578f4965afb875148854c19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce275d58b21041539f574c442bdf770e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94e63ca1801461cb71d4980c705ddb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c8ff1ce271b4e8db2a3dbfab0d94e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041bdd8faa8a456d94b1cf2f33ab296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b429b9370fa042d9b200a42b1a1300a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d13b4f3084fe4176a83b67a67b456c8d",
              "IPY_MODEL_ef23fc347a934472ac15f1e0605a4df9",
              "IPY_MODEL_e4982b49fa3148a189b278f1c7d933db"
            ],
            "layout": "IPY_MODEL_2e5c2f5ba6f2463f9ce01eb96772c794"
          }
        },
        "d13b4f3084fe4176a83b67a67b456c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d5637dc8c946b2b53aaa672e9bbcc6",
            "placeholder": "​",
            "style": "IPY_MODEL_fee7442350e94ef982a2c247da15333a",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "ef23fc347a934472ac15f1e0605a4df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8412b769bc52454fb37646da0986b43b",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d93553cee1340dabe123552a924317c",
            "value": 53
          }
        },
        "e4982b49fa3148a189b278f1c7d933db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c008b4f452244f589a5c736c705e081e",
            "placeholder": "​",
            "style": "IPY_MODEL_24e6c3cc5d484052a651482dcf99ff4b",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.70kB/s]"
          }
        },
        "2e5c2f5ba6f2463f9ce01eb96772c794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d5637dc8c946b2b53aaa672e9bbcc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee7442350e94ef982a2c247da15333a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8412b769bc52454fb37646da0986b43b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d93553cee1340dabe123552a924317c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c008b4f452244f589a5c736c705e081e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e6c3cc5d484052a651482dcf99ff4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15b7015d81ae41bb8f8b9d14a7debb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66a654d1088e4652a64c27e53cd60708",
              "IPY_MODEL_122ea06d1c1e4a25970a438a36aa9a8d",
              "IPY_MODEL_3f8358aa869b4c759d4e1664b807214c"
            ],
            "layout": "IPY_MODEL_7df9a3da1c884f1da46dd79ff34ab5f6"
          }
        },
        "66a654d1088e4652a64c27e53cd60708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d9284de3184d7f85dc40eac64a6a02",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a847b27d84431f97491e71911135af",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "122ea06d1c1e4a25970a438a36aa9a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2fc0f3b240471383aeb75e71bce5ff",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2db148b066345e28ae897a817a44b4f",
            "value": 112
          }
        },
        "3f8358aa869b4c759d4e1664b807214c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e73eba4187dd4f68b97392f8a3561428",
            "placeholder": "​",
            "style": "IPY_MODEL_621166a8ef314bceabf0f46bb2ae3aaf",
            "value": " 112/112 [00:00&lt;00:00, 7.86kB/s]"
          }
        },
        "7df9a3da1c884f1da46dd79ff34ab5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d9284de3184d7f85dc40eac64a6a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a847b27d84431f97491e71911135af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b2fc0f3b240471383aeb75e71bce5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2db148b066345e28ae897a817a44b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e73eba4187dd4f68b97392f8a3561428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "621166a8ef314bceabf0f46bb2ae3aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96492d7a6353498a8c52c090dfc40dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9ee923a0b1a4380ab3f88bb0aa70aef",
              "IPY_MODEL_869b0871847c421d8eaa317ce2e2bb61",
              "IPY_MODEL_48bb7d9238a144e5ae1d55c5a6f70ece"
            ],
            "layout": "IPY_MODEL_d93123f23af34dc4aa5b82a8357f4eae"
          }
        },
        "b9ee923a0b1a4380ab3f88bb0aa70aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf695e743b9a4525bcc14ddd0edd1f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_5f1ab2b209a54ab5a0074450f5636e04",
            "value": "tokenizer.json: 100%"
          }
        },
        "869b0871847c421d8eaa317ce2e2bb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3fbe2799abd46798fa07f269b780f67",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9208af66ab7d4e409da1bd0a56bdbbb2",
            "value": 466247
          }
        },
        "48bb7d9238a144e5ae1d55c5a6f70ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3cf3db01324a1bb6c24b96e66fbae9",
            "placeholder": "​",
            "style": "IPY_MODEL_f9eea919efa04bea9b35d3d353f96c00",
            "value": " 466k/466k [00:00&lt;00:00, 3.34MB/s]"
          }
        },
        "d93123f23af34dc4aa5b82a8357f4eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf695e743b9a4525bcc14ddd0edd1f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f1ab2b209a54ab5a0074450f5636e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3fbe2799abd46798fa07f269b780f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9208af66ab7d4e409da1bd0a56bdbbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c3cf3db01324a1bb6c24b96e66fbae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9eea919efa04bea9b35d3d353f96c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd5e42f4b44466ea60feef5f3420d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26bebae6eb8e4a68a4b89c8a5c2fb892",
              "IPY_MODEL_5205e20e3571406a87ff684ff8486db7",
              "IPY_MODEL_75e2ab8a72de4f73aa6a5057f66f707e"
            ],
            "layout": "IPY_MODEL_7977d6a6af774f4589280ff14525830d"
          }
        },
        "26bebae6eb8e4a68a4b89c8a5c2fb892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5726f6a71196416f8d07dfcb118d50b4",
            "placeholder": "​",
            "style": "IPY_MODEL_dc247ce3e50246f4b5eea2c1851f128f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5205e20e3571406a87ff684ff8486db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4018742044e449a3b39298565745056b",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_649e6a421e744aa0857d1654c65d7f53",
            "value": 350
          }
        },
        "75e2ab8a72de4f73aa6a5057f66f707e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d4ed45384e491594a2389596d81800",
            "placeholder": "​",
            "style": "IPY_MODEL_bb6a014185c34c32ab4de4fe497aea5d",
            "value": " 350/350 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "7977d6a6af774f4589280ff14525830d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5726f6a71196416f8d07dfcb118d50b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc247ce3e50246f4b5eea2c1851f128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4018742044e449a3b39298565745056b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649e6a421e744aa0857d1654c65d7f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77d4ed45384e491594a2389596d81800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb6a014185c34c32ab4de4fe497aea5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd6e4ba423c04cbf869245aa3726dbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_796629a6c122400a94c609e7cd6ae848",
              "IPY_MODEL_dc5a0027aac7423f9104051ade887df1",
              "IPY_MODEL_ca527aaeea324926a4173ad4304dce15"
            ],
            "layout": "IPY_MODEL_3af04179ad924547b7a3ee3b59733237"
          }
        },
        "796629a6c122400a94c609e7cd6ae848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e6fdb8fdcea48baa7c40cf5ef75467b",
            "placeholder": "​",
            "style": "IPY_MODEL_92f25132d2cb432ca56464751c3a16f9",
            "value": "train_script.py: 100%"
          }
        },
        "dc5a0027aac7423f9104051ade887df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211d5383156141d6b745092fcd89c94b",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22e65d0e354c4c69a5b8bdc922edebac",
            "value": 13156
          }
        },
        "ca527aaeea324926a4173ad4304dce15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb77754689543fcb26830630d939f4e",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3fb7b213fc4e3eb18c91ad5bf350b0",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 754kB/s]"
          }
        },
        "3af04179ad924547b7a3ee3b59733237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6fdb8fdcea48baa7c40cf5ef75467b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f25132d2cb432ca56464751c3a16f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "211d5383156141d6b745092fcd89c94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e65d0e354c4c69a5b8bdc922edebac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbb77754689543fcb26830630d939f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3fb7b213fc4e3eb18c91ad5bf350b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85ef19cadc9c49db81e19b01014784b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9341a31fc2f246cfa689d3bd32826f51",
              "IPY_MODEL_d0eb9d02362d4f65bd21a51bc61c1b76",
              "IPY_MODEL_b48ce13e0299496285489c7a30003d74"
            ],
            "layout": "IPY_MODEL_98a561696256476ba8956ee718d6559d"
          }
        },
        "9341a31fc2f246cfa689d3bd32826f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9db18911785464fb567186d4af0e324",
            "placeholder": "​",
            "style": "IPY_MODEL_f99ca24bf98045b3b130e2f37838b9b7",
            "value": "vocab.txt: 100%"
          }
        },
        "d0eb9d02362d4f65bd21a51bc61c1b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8877e117f2824f14a52c0e861a76b885",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc7d17eb70bd436d9d9ae2e8d3dfe21c",
            "value": 231508
          }
        },
        "b48ce13e0299496285489c7a30003d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5fffaf70989412dbf645667a3d1ae88",
            "placeholder": "​",
            "style": "IPY_MODEL_342bd321e2eb489daa060192f1f7be89",
            "value": " 232k/232k [00:00&lt;00:00, 3.23MB/s]"
          }
        },
        "98a561696256476ba8956ee718d6559d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9db18911785464fb567186d4af0e324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99ca24bf98045b3b130e2f37838b9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8877e117f2824f14a52c0e861a76b885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7d17eb70bd436d9d9ae2e8d3dfe21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5fffaf70989412dbf645667a3d1ae88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "342bd321e2eb489daa060192f1f7be89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b325f61bbdf645fda2cf98a84612e0ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b10e1bc9f6ac466fb5dce61a0d70ef27",
              "IPY_MODEL_9dbe6bb9c3fa492a8d5b3022415d4cc8",
              "IPY_MODEL_16ecdfb3c30e4d998ae8de2324d64060"
            ],
            "layout": "IPY_MODEL_2bd69a92c4d34604a3e53448db63857c"
          }
        },
        "b10e1bc9f6ac466fb5dce61a0d70ef27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfe11f56c264351a7d07566a67006cf",
            "placeholder": "​",
            "style": "IPY_MODEL_d72e89e2fe6947c98fd1ffb5c8beee1b",
            "value": "modules.json: 100%"
          }
        },
        "9dbe6bb9c3fa492a8d5b3022415d4cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9f321408f248dc86da00310e3eaf8f",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee0444204e404fa6b664da1f7750c49b",
            "value": 349
          }
        },
        "16ecdfb3c30e4d998ae8de2324d64060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848aa9c61c7f408fb2bc5beb71fc6dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_012d042a834d4767a86f995240cadcc8",
            "value": " 349/349 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "2bd69a92c4d34604a3e53448db63857c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfe11f56c264351a7d07566a67006cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72e89e2fe6947c98fd1ffb5c8beee1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e9f321408f248dc86da00310e3eaf8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0444204e404fa6b664da1f7750c49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "848aa9c61c7f408fb2bc5beb71fc6dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "012d042a834d4767a86f995240cadcc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}